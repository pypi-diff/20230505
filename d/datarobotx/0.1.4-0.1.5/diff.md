# Comparing `tmp/datarobotx-0.1.4-py3-none-any.whl.zip` & `tmp/datarobotx-0.1.5-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,51 +1,58 @@
-Zip file size: 125855 bytes, number of entries: 49
--rw-rw-r--  2.0 unx     1499 b- defN 23-Apr-14 19:28 datarobotx/__init__.py
--rw-rw-r--  2.0 unx      271 b- defN 23-Apr-14 19:28 datarobotx/_version.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Apr-14 19:28 datarobotx/py.typed
--rw-rw-r--  2.0 unx        0 b- defN 23-Apr-14 19:28 datarobotx/client/__init__.py
--rw-rw-r--  2.0 unx     9402 b- defN 23-Apr-14 19:28 datarobotx/client/datasets.py
--rw-rw-r--  2.0 unx    14621 b- defN 23-Apr-14 19:28 datarobotx/client/deployments.py
--rw-rw-r--  2.0 unx     1002 b- defN 23-Apr-14 19:28 datarobotx/client/prediction_servers.py
--rw-rw-r--  2.0 unx    24966 b- defN 23-Apr-14 19:28 datarobotx/client/projects.py
--rw-rw-r--  2.0 unx     2420 b- defN 23-Apr-14 19:28 datarobotx/client/status.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Apr-14 19:28 datarobotx/common/__init__.py
--rw-rw-r--  2.0 unx     5980 b- defN 23-Apr-14 19:28 datarobotx/common/client.py
--rw-rw-r--  2.0 unx     9306 b- defN 23-Apr-14 19:28 datarobotx/common/config.py
--rw-rw-r--  2.0 unx     4588 b- defN 23-Apr-14 19:28 datarobotx/common/configurator.py
--rw-rw-r--  2.0 unx   131191 b- defN 23-Apr-14 19:28 datarobotx/common/dr_config.py
--rw-rw-r--  2.0 unx    10490 b- defN 23-Apr-14 19:28 datarobotx/common/logging.py
--rw-rw-r--  2.0 unx     3980 b- defN 23-Apr-14 19:28 datarobotx/common/transformations.py
--rw-rw-r--  2.0 unx    25914 b- defN 23-Apr-14 19:28 datarobotx/common/utils.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Apr-14 19:28 datarobotx/models/__init__.py
--rw-rw-r--  2.0 unx     2754 b- defN 23-Apr-14 19:28 datarobotx/models/autoanomaly.py
--rw-rw-r--  2.0 unx     3332 b- defN 23-Apr-14 19:28 datarobotx/models/autocluster.py
--rw-rw-r--  2.0 unx     2465 b- defN 23-Apr-14 19:28 datarobotx/models/automl.py
--rw-rw-r--  2.0 unx    11349 b- defN 23-Apr-14 19:28 datarobotx/models/autopilot.py
--rw-rw-r--  2.0 unx     6784 b- defN 23-Apr-14 19:28 datarobotx/models/autots.py
--rw-rw-r--  2.0 unx    14976 b- defN 23-Apr-14 19:28 datarobotx/models/colreduce.py
--rw-rw-r--  2.0 unx    24227 b- defN 23-Apr-14 19:28 datarobotx/models/deploy.py
--rw-rw-r--  2.0 unx    29549 b- defN 23-Apr-14 19:28 datarobotx/models/deployment.py
--rw-rw-r--  2.0 unx     7869 b- defN 23-Apr-14 19:28 datarobotx/models/evaluation.py
--rw-rw-r--  2.0 unx    16937 b- defN 23-Apr-14 19:28 datarobotx/models/featurediscovery.py
--rw-rw-r--  2.0 unx     5593 b- defN 23-Apr-14 19:28 datarobotx/models/intraproject.py
--rw-rw-r--  2.0 unx    26732 b- defN 23-Apr-14 19:28 datarobotx/models/model.py
--rw-rw-r--  2.0 unx     9736 b- defN 23-Apr-14 19:28 datarobotx/models/selfdiscovery.py
--rw-rw-r--  2.0 unx     4422 b- defN 23-Apr-14 19:28 datarobotx/models/share.py
--rw-rw-r--  2.0 unx    20800 b- defN 23-Apr-14 19:28 datarobotx/models/sparkingest.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Apr-14 19:28 datarobotx/viz/__init__.py
--rw-rw-r--  2.0 unx     4906 b- defN 23-Apr-14 19:28 datarobotx/viz/charts.py
--rw-rw-r--  2.0 unx     6379 b- defN 23-Apr-14 19:28 datarobotx/viz/leaderboard.py
--rw-rw-r--  2.0 unx     9407 b- defN 23-Apr-14 19:28 datarobotx/viz/modelcard.py
--rw-rw-r--  2.0 unx     9508 b- defN 23-Apr-14 19:28 datarobotx/viz/viz.py
--rw-rw-r--  2.0 unx      926 b- defN 23-Apr-14 19:28 datarobotx/viz/templates/drx_button.html
--rw-rw-r--  2.0 unx     1490 b- defN 23-Apr-14 19:28 datarobotx/viz/templates/leaderboard.html
--rw-rw-r--  2.0 unx      414 b- defN 23-Apr-14 19:28 datarobotx/viz/templates/leaderboard.md
--rw-rw-r--  2.0 unx     5433 b- defN 23-Apr-14 19:28 datarobotx/viz/templates/model_card.html
--rw-rw-r--  2.0 unx       48 b- defN 23-Apr-14 19:28 datarobotx/viz/templates/model_card.md
--rw-rw-r--  2.0 unx     3140 b- defN 23-Apr-14 19:28 datarobotx/viz/templates/robot.svg
--rw-rw-r--  2.0 unx     3135 b- defN 23-Apr-14 19:28 datarobotx/viz/templates/robot_large.svg
--rw-rw-r--  2.0 unx     4733 b- defN 23-Apr-14 19:30 datarobotx-0.1.4.dist-info/METADATA
--rw-rw-r--  2.0 unx       92 b- defN 23-Apr-14 19:30 datarobotx-0.1.4.dist-info/WHEEL
--rw-rw-r--  2.0 unx       11 b- defN 23-Apr-14 19:30 datarobotx-0.1.4.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     4235 b- defN 23-Apr-14 19:30 datarobotx-0.1.4.dist-info/RECORD
-49 files, 487012 bytes uncompressed, 119095 bytes compressed:  75.5%
+Zip file size: 141241 bytes, number of entries: 56
+-rw-rw-r--  2.0 unx     1566 b- defN 23-May-04 23:52 datarobotx/__init__.py
+-rw-rw-r--  2.0 unx      271 b- defN 23-May-04 23:52 datarobotx/_version.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-May-04 23:52 datarobotx/py.typed
+-rw-rw-r--  2.0 unx        0 b- defN 23-May-04 23:52 datarobotx/client/__init__.py
+-rw-rw-r--  2.0 unx     9402 b- defN 23-May-04 23:52 datarobotx/client/datasets.py
+-rw-rw-r--  2.0 unx    15368 b- defN 23-May-04 23:52 datarobotx/client/deployments.py
+-rw-rw-r--  2.0 unx     1002 b- defN 23-May-04 23:52 datarobotx/client/prediction_servers.py
+-rw-rw-r--  2.0 unx    25695 b- defN 23-May-04 23:52 datarobotx/client/projects.py
+-rw-rw-r--  2.0 unx     2420 b- defN 23-May-04 23:52 datarobotx/client/status.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-May-04 23:52 datarobotx/common/__init__.py
+-rw-rw-r--  2.0 unx     7273 b- defN 23-May-04 23:52 datarobotx/common/client.py
+-rw-rw-r--  2.0 unx     8741 b- defN 23-May-04 23:52 datarobotx/common/config.py
+-rw-rw-r--  2.0 unx     4588 b- defN 23-May-04 23:52 datarobotx/common/configurator.py
+-rw-rw-r--  2.0 unx   131191 b- defN 23-May-04 23:52 datarobotx/common/dr_config.py
+-rw-rw-r--  2.0 unx    10494 b- defN 23-May-04 23:52 datarobotx/common/logging.py
+-rw-rw-r--  2.0 unx     3980 b- defN 23-May-04 23:52 datarobotx/common/transformations.py
+-rw-rw-r--  2.0 unx    15032 b- defN 23-May-04 23:52 datarobotx/common/ts_helpers.py
+-rw-rw-r--  2.0 unx      605 b- defN 23-May-04 23:52 datarobotx/common/types.py
+-rw-rw-r--  2.0 unx    26936 b- defN 23-May-04 23:52 datarobotx/common/utils.py
+-rw-rw-r--  2.0 unx      136 b- defN 23-May-04 23:52 datarobotx/llm/__init__.py
+-rw-rw-r--  2.0 unx     2119 b- defN 23-May-04 23:52 datarobotx/llm/utils.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-May-04 23:52 datarobotx/llm/chains/__init__.py
+-rw-rw-r--  2.0 unx    11994 b- defN 23-May-04 23:52 datarobotx/llm/chains/data_dict.py
+-rw-rw-r--  2.0 unx     9398 b- defN 23-May-04 23:52 datarobotx/llm/chains/enrich.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-May-04 23:52 datarobotx/models/__init__.py
+-rw-rw-r--  2.0 unx     2754 b- defN 23-May-04 23:52 datarobotx/models/autoanomaly.py
+-rw-rw-r--  2.0 unx     3332 b- defN 23-May-04 23:52 datarobotx/models/autocluster.py
+-rw-rw-r--  2.0 unx     2465 b- defN 23-May-04 23:52 datarobotx/models/automl.py
+-rw-rw-r--  2.0 unx    11349 b- defN 23-May-04 23:52 datarobotx/models/autopilot.py
+-rw-rw-r--  2.0 unx    11242 b- defN 23-May-04 23:52 datarobotx/models/autots.py
+-rw-rw-r--  2.0 unx    14976 b- defN 23-May-04 23:52 datarobotx/models/colreduce.py
+-rw-rw-r--  2.0 unx    24227 b- defN 23-May-04 23:52 datarobotx/models/deploy.py
+-rw-rw-r--  2.0 unx    33947 b- defN 23-May-04 23:52 datarobotx/models/deployment.py
+-rw-rw-r--  2.0 unx     7914 b- defN 23-May-04 23:52 datarobotx/models/evaluation.py
+-rw-rw-r--  2.0 unx    16937 b- defN 23-May-04 23:52 datarobotx/models/featurediscovery.py
+-rw-rw-r--  2.0 unx     5593 b- defN 23-May-04 23:52 datarobotx/models/intraproject.py
+-rw-rw-r--  2.0 unx    28420 b- defN 23-May-04 23:52 datarobotx/models/model.py
+-rw-rw-r--  2.0 unx     9736 b- defN 23-May-04 23:52 datarobotx/models/selfdiscovery.py
+-rw-rw-r--  2.0 unx     4422 b- defN 23-May-04 23:52 datarobotx/models/share.py
+-rw-rw-r--  2.0 unx    20800 b- defN 23-May-04 23:52 datarobotx/models/sparkingest.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-May-04 23:52 datarobotx/viz/__init__.py
+-rw-rw-r--  2.0 unx     4906 b- defN 23-May-04 23:52 datarobotx/viz/charts.py
+-rw-rw-r--  2.0 unx     6326 b- defN 23-May-04 23:52 datarobotx/viz/leaderboard.py
+-rw-rw-r--  2.0 unx     9407 b- defN 23-May-04 23:52 datarobotx/viz/modelcard.py
+-rw-rw-r--  2.0 unx     9508 b- defN 23-May-04 23:52 datarobotx/viz/viz.py
+-rw-rw-r--  2.0 unx      926 b- defN 23-May-04 23:52 datarobotx/viz/templates/drx_button.html
+-rw-rw-r--  2.0 unx     1490 b- defN 23-May-04 23:52 datarobotx/viz/templates/leaderboard.html
+-rw-rw-r--  2.0 unx      414 b- defN 23-May-04 23:52 datarobotx/viz/templates/leaderboard.md
+-rw-rw-r--  2.0 unx     5433 b- defN 23-May-04 23:52 datarobotx/viz/templates/model_card.html
+-rw-rw-r--  2.0 unx       48 b- defN 23-May-04 23:52 datarobotx/viz/templates/model_card.md
+-rw-rw-r--  2.0 unx     3140 b- defN 23-May-04 23:52 datarobotx/viz/templates/robot.svg
+-rw-rw-r--  2.0 unx     3135 b- defN 23-May-04 23:52 datarobotx/viz/templates/robot_large.svg
+-rw-rw-r--  2.0 unx     5330 b- defN 23-May-04 23:53 datarobotx-0.1.5.dist-info/METADATA
+-rw-rw-r--  2.0 unx       92 b- defN 23-May-04 23:53 datarobotx-0.1.5.dist-info/WHEEL
+-rw-rw-r--  2.0 unx       11 b- defN 23-May-04 23:53 datarobotx-0.1.5.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     4836 b- defN 23-May-04 23:53 datarobotx-0.1.5.dist-info/RECORD
+56 files, 541327 bytes uncompressed, 133541 bytes compressed:  75.3%
```

## zipnote {}

```diff
@@ -42,17 +42,38 @@
 
 Filename: datarobotx/common/logging.py
 Comment: 
 
 Filename: datarobotx/common/transformations.py
 Comment: 
 
+Filename: datarobotx/common/ts_helpers.py
+Comment: 
+
+Filename: datarobotx/common/types.py
+Comment: 
+
 Filename: datarobotx/common/utils.py
 Comment: 
 
+Filename: datarobotx/llm/__init__.py
+Comment: 
+
+Filename: datarobotx/llm/utils.py
+Comment: 
+
+Filename: datarobotx/llm/chains/__init__.py
+Comment: 
+
+Filename: datarobotx/llm/chains/data_dict.py
+Comment: 
+
+Filename: datarobotx/llm/chains/enrich.py
+Comment: 
+
 Filename: datarobotx/models/__init__.py
 Comment: 
 
 Filename: datarobotx/models/autoanomaly.py
 Comment: 
 
 Filename: datarobotx/models/autocluster.py
@@ -129,20 +150,20 @@
 
 Filename: datarobotx/viz/templates/robot.svg
 Comment: 
 
 Filename: datarobotx/viz/templates/robot_large.svg
 Comment: 
 
-Filename: datarobotx-0.1.4.dist-info/METADATA
+Filename: datarobotx-0.1.5.dist-info/METADATA
 Comment: 
 
-Filename: datarobotx-0.1.4.dist-info/WHEEL
+Filename: datarobotx-0.1.5.dist-info/WHEEL
 Comment: 
 
-Filename: datarobotx-0.1.4.dist-info/top_level.txt
+Filename: datarobotx-0.1.5.dist-info/top_level.txt
 Comment: 
 
-Filename: datarobotx-0.1.4.dist-info/RECORD
+Filename: datarobotx-0.1.5.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## datarobotx/__init__.py

```diff
@@ -37,11 +37,17 @@
 from .models.evaluation import evaluate, import_parametric_model
 from .models.featurediscovery import FeatureDiscoveryModel, Relationship
 from .models.model import Model
 from .models.selfdiscovery import SelfDiscoveryModel
 from .models.share import share
 
 try:
+    from datarobotx import llm
+except ImportError:
+    pass
+
+try:
     from .models.sparkingest import downsample_spark, spark_to_ai_catalog, SparkIngestModel
 except ImportError:
     pass
+
 from ._version import __version__ as VERSION
```

## datarobotx/_version.py

```diff
@@ -6,8 +6,8 @@
 # DataRobot, Inc.
 #
 # This is proprietary source code of DataRobot, Inc. and its
 # affiliates.
 #
 # Released under the terms of DataRobot Tool and Utility Agreement.
 #
-__version__ = "0.1.4"
+__version__ = "0.1.5"
```

## datarobotx/client/deployments.py

```diff
@@ -20,14 +20,15 @@
 
 from datarobotx.client.datasets import get_dataset, get_dataset_file
 from datarobotx.client.prediction_servers import get_default_pred_server
 from datarobotx.client.status import await_status, poll
 from datarobotx.common.client import raise_value_error, read_resp_data, session
 from datarobotx.common.config import context
 from datarobotx.common.logging import tqdm
+from datarobotx.common.types import TimeSeriesPredictParams
 from datarobotx.common.utils import FilesSender, log_when_complete
 
 logger = logging.getLogger("drx")
 
 
 async def get_deployment(did: str) -> Dict[str, Any]:
     """Returns the details for a deployment given a deployment id"""
@@ -221,30 +222,37 @@
 
 
 async def post_predictions(
     did: str,
     dr_key: str,
     pred_server_endpoint: str,
     payload: Tuple[str, pd.DataFrame],
+    ts_params: Optional[TimeSeriesPredictParams] = None,
     max_explanations: Optional[int] = None,
     explanation_num_top_classes: Optional[int] = None,
 ) -> pd.DataFrame:
     """
     Make predictions on a deployment.
     Parameters:
     ----------
     max_explanations: int or 'all' (default=None)
         Number of explanations to return for each prediction
     """
     logger.info("Uploading dataset to be scored...")
-    params = {}
+    params: Dict[str, Any] = {}
     if max_explanations is not None:
         params["maxExplanations"] = max_explanations
     if explanation_num_top_classes is not None:
         params["explanationNumTopClasses"] = explanation_num_top_classes
+    if ts_params is not None:
+        params.update(ts_params)
+        if params.get("relaxKnownInAdvanceFeaturesCheck") is not None:
+            params["relaxKnownInAdvanceFeaturesCheck"] = str(
+                params["relaxKnownInAdvanceFeaturesCheck"]
+            ).lower()
 
     url = f"{pred_server_endpoint}/deployments/{did}/predictions"
     pred_headers = {"DataRobot-Key": dr_key, "Accept": "text/csv"}
     file_name, _ = payload
     form_data = aiohttp.FormData()
     sender = FilesSender(payload)
     form_data.add_field(
@@ -288,33 +296,40 @@
         return_data = await resp.text()
         return cast(Dict[str, Any], json.loads(return_data))
 
 
 async def post_batch_predictions(
     did: str,
     payload: Tuple[str, pd.DataFrame],
+    ts_params: Optional[TimeSeriesPredictParams] = None,
     max_explanations: Optional[int] = None,
     explanation_num_top_classes: Optional[List[str]] = None,
 ) -> str:
     """Makes batch predictions on a deployment"""
     logger.info("Uploading dataset to be scored...")
     if max_explanations is None:
         max_explanations = 0
     url = "/batchPredictions/"
     file_name, _ = payload
     sender = FilesSender(payload)
-    jobSpec = {
+    jobSpec: Dict[str, Any] = {
         "deploymentId": did,
         "intakeSettings": {"type": "localFile"},
         "outputSettings": {"type": "localFile"},
         "maxExplanations": max_explanations,
     }
     if max_explanations > 0 and explanation_num_top_classes:
         jobSpec["explanationNumTopClasses"] = explanation_num_top_classes
 
+    if ts_params:
+        # Special configuration for batch jobs
+        ts_params["type"] = "historical" if "predictionsStartDate" in ts_params else "forecast"
+        ts_upload_params = {"timeseriesSettings": ts_params}
+        jobSpec.update(ts_upload_params)
+
     async with session.post(url, json=jobSpec) as resp:
         if resp.status != 202:
             await raise_value_error(resp)
         else:
             full_resp = await resp.json()
             job_url = full_resp["links"]["self"]
             csv_up = full_resp["links"]["csvUpload"]
```

## datarobotx/client/projects.py

```diff
@@ -10,15 +10,15 @@
 #
 # Released under the terms of DataRobot Tool and Utility Agreement.
 from collections.abc import Callable
 import io
 import json
 import logging
 from typing import Any, cast, Dict, List, Optional, Tuple
-from urllib.parse import urlencode
+from urllib.parse import quote, urlencode
 
 import aiohttp
 import pandas as pd
 
 from datarobotx.client.status import await_status, poll
 from datarobotx.common.client import raise_value_error, read_resp_data, session
 from datarobotx.common.logging import refresh_bar, tqdm
@@ -233,62 +233,67 @@
     url = f"/projects/{pid}/predictionDatasets/{ds_id}/"
     async with session.get(url, allow_redirects=False) as resp:
         json = await resp.json()
         return cast(Dict[str, Any], json)
 
 
 async def post_prediction_datasets_file_uploads(
-    pid: str, payload: Tuple[str, pd.DataFrame]
+    pid: str, payload: Tuple[str, pd.DataFrame], relax_kia_check: bool = False
 ) -> Dict[str, Any]:
     """Upload a new prediction dataset to DR."""
     logger.info("Uploading prediction dataset...")
     file_name, _ = payload
     sender = FilesSender(payload)
 
     url = f"/projects/{pid}/predictionDatasets/fileUploads/"
     form_data = aiohttp.FormData()
     form_data.add_field("file", sender.reader(file_name), filename=file_name)
+
+    # For time series projects
+    if relax_kia_check:
+        form_data.add_field("relaxKnownInAdvanceFeaturesCheck", "true")
+
     async with session.post(url, data=form_data, timeout=None) as resp:
         status_url = resp.headers["Location"]
     logger.info("Awaiting prediction dataset initialization...")
 
     ds_id = await poll(await_status, coro_args=[status_url])
     ds_json = await get_prediction_dataset(pid=pid, ds_id=ds_id)
     return ds_json
 
 
-async def post_prediction_datasets_dataset_uploads(pid: str, dataset_id: str) -> Dict[str, Any]:
+async def post_prediction_datasets_dataset_uploads(
+    pid: str, dataset_id: str, relax_kia_check: bool = False
+) -> Dict[str, Any]:
     """Upload a new prediction dataset to DR."""
     url = f"/projects/{pid}/predictionDatasets/datasetUploads/"
-    async with session.post(url, json={"datasetId": dataset_id}, timeout=None) as resp:
+    json = {"datasetId": dataset_id}
+
+    if relax_kia_check:
+        json["relaxKnownInAdvanceFeaturesCheck"] = "true"
+
+    async with session.post(url, json=json, timeout=None) as resp:
         status_url = resp.headers["Location"]
     logger.info("Awaiting prediction dataset initialization...")
 
     ds_id = await poll(await_status, coro_args=[status_url])
     ds_json = await get_prediction_dataset(pid=pid, ds_id=ds_id)
     return ds_json
 
 
-async def post_predictions(
-    pid: str, model_id: str, ds_id: str, date_range: Optional[List[str]] = None
-) -> str:
-    """Request and await DataRobot predictions"""
-    start_predictions_url = f"/projects/{pid}/predictions/"
-    json = {"modelId": model_id, "datasetId": ds_id}
-    if date_range is not None and date_range[0] != date_range[1]:
-        # json["predictionsStartDate"] = date_range[0] # This is for historical predictions
-        # json["predictionsEndDate"] = date_range[1]
-        # json["forecastPoint"] = date_range[1]
-        pass
+async def post_predictions(pid: str, json: Dict[str, Any]) -> str:
+    """
+    Request and await DataRobot predictions
+    """
+    start_predictions_url = "/projects/" + pid + "/predictions/"
 
     async with session.post(start_predictions_url, json=json) as resp:
         if resp.status != 202:
             await raise_value_error(resp)
         pred_status_url = resp.headers["Location"]
-
     logger.info("Scoring...")
 
     preds_id = await poll(await_status, coro_args=[pred_status_url])
     return cast(str, preds_id)
 
 
 async def post_external_scores(pid: str, model_id: str, prediction_dataset_id: str) -> str:
@@ -413,14 +418,26 @@
     return json
 
 
 async def get_features(pid: str) -> Dict[str, Any]:
     """Retrieve list of features for a given project id."""
     url = f"/projects/{pid}/features/"
     async with session.get(url, allow_redirects=False) as resp:
+        if resp.status != 200:
+            await raise_value_error(resp)
+        json = await resp.json()
+        return cast(Dict[str, Any], json)
+
+
+async def get_feature_histogram(pid: str, feature: str) -> Dict[str, Any]:
+    """Retrieve feature histogram for a feature from a project."""
+    url = f"/projects/{pid}/featureHistograms/{quote(feature)}"
+    async with session.get(url) as resp:
+        if resp.status != 200:
+            await raise_value_error(resp)
         json = await resp.json()
         return cast(Dict[str, Any], json)
 
 
 async def get_featurelist(pid: str, featurelist_id: str) -> Dict[str, Any]:
     """Retrieve featurelist details for a given project_id, featurelist_id."""
     url = f"/projects/{pid}/featurelists/{featurelist_id}/"
@@ -598,14 +615,23 @@
                 + "Note that download of the feature discovery dataset is not available until Autopilot has fully "
                 "initialized and started."
             )
         response = await resp.text()
         return pd.read_csv(io.StringIO(response), sep=",")
 
 
+async def get_datetime_partitioning(pid: str) -> Dict[str, Any]:
+    """Get time unit and time step of each series"""
+    url = f"/projects/{pid}/datetimePartitioning"
+    async with session.get(url) as resp:
+        if resp.status != 200:
+            await raise_value_error(resp)
+        return await resp.json()
+
+
 async def get_blueprints(pid: str) -> Dict[str, Any]:
     """Get a list of blueprints from a modeling project"""
     url = f"/projects/{pid}/blueprints/"
     async with session.get(url) as resp:
         if resp.status != 200:
             raise ValueError(
                 f"Received error code {resp.status} from GET '{url}'."
```

## datarobotx/common/client.py

```diff
@@ -6,25 +6,29 @@
 # DataRobot, Inc.
 #
 # This is proprietary source code of DataRobot, Inc. and its
 # affiliates.
 #
 # Released under the terms of DataRobot Tool and Utility Agreement.
 import io
+import logging
 import platform
 import re
+import textwrap
 import threading
-from typing import Any, cast, Coroutine, Dict, Mapping, Tuple
+from typing import Any, Awaitable, Callable, cast, Coroutine, Dict, Mapping, Tuple
 
 import aiohttp
+import tenacity
 import tqdm
 
 from datarobotx._version import __version__ as VERSION
 from datarobotx.common.config import context, drx_task_entry_point
 
+logger = logging.getLogger("drx")
 _local = threading.local()
 _local.session = None
 
 
 class Session:
     """Wraps aiohttp.ClientSession and implements get, post, etc.,
     managing the session and constructing full URLs."""
@@ -120,16 +124,26 @@
         dr_message = json["message"]
         message += f' Message: "{dr_message}"'
         if "errors" in json:
             errors = str(json["errors"])
             message += f' Errors: "{errors}"'
     except Exception:
         pass
-
-    raise ValueError(message)
+    message = "\n".join(
+        textwrap.wrap(
+            message,
+            width=100,
+            subsequent_indent="    ",
+            break_on_hyphens=False,
+            break_long_words=False,
+        )
+    )
+    e = ValueError(message)
+    setattr(e, "status", resp.status)
+    raise e
 
 
 def raise_timeout_error(
     timeout: float, coro: Coroutine, coro_args: Tuple[Any], coro_kwargs: Mapping[str, Any]  # type: ignore[type-arg]
 ) -> None:
     """Raise a runtime error if polling has timed out"""
     qualname = coro.__qualname__
@@ -166,7 +180,37 @@
 
     Designed to be easily mocked due to:
     https://github.com/kevin1024/vcrpy/issues/502
     """
     async for data in resp.content.iter_chunked(1024):
         f.write(data)
         pbar.update(len(data))
+
+
+async def retry_if_too_many_attempts(  # type: ignore[no-untyped-def]
+    coro: Callable[..., Awaitable[Any]], *args, **kwargs
+) -> Awaitable[Any]:
+    """Wrapper to retry a coroutine if HTTP 429 encountered
+
+    e.g. too many attempts
+    """
+
+    class DrxTooManyAttempts(Exception):
+        pass
+
+    @tenacity.retry(  # type: ignore[misc]
+        reraise=True,
+        stop=tenacity.stop_after_attempt(10),
+        wait=tenacity.wait_exponential(multiplier=1, min=1, max=10),
+        retry=tenacity.retry_if_exception_type(DrxTooManyAttempts),
+    )
+    async def retry_wrapper() -> Awaitable[Any]:
+        try:
+            return await coro(*args, **kwargs)
+        except ValueError as e:
+            try:
+                assert getattr(e, "status", None) == 429
+                raise DrxTooManyAttempts("Received HTTP 429")
+            except AssertionError:
+                raise e
+
+    return await retry_wrapper()
```

## datarobotx/common/config.py

```diff
@@ -27,20 +27,14 @@
 
 _theme = contextvars.ContextVar("theme", default="dark")
 
 _concurrency_poll_interval = contextvars.ContextVar("concurrency_poll_interval", default=0.2)
 
 _max_dr_ingest = contextvars.ContextVar("max_dr_ingest", default=5 * (10**9))
 
-# TODO: update to new DR-notebook-identifying env variable once NB-2599 complete
-_notebooks_remove_ipy_widgets = contextvars.ContextVar(
-    "notebooks_remove_ipy_widgets", default="DATAROBOT_API_KEY_ID" in os.environ
-)
-
-
 # Context variable for the public entry point (function name) into threaded drx work
 drx_task_entry_point: contextvars.ContextVar[str] = contextvars.ContextVar("drx_task_entry_point")
 
 
 def is_notebook_env() -> bool:
     """Detect if this is an interactive, ipython-based notebook"""
     try:
@@ -259,19 +253,9 @@
         """Whether charts render in dark or light"""
         return _theme.get()
 
     @theme.setter
     def theme(self, value: str) -> None:
         _theme.set(value)
 
-    @property
-    def _notebooks_remove_ipy_widgets(self) -> bool:
-        """Whether to allow ipywidgets to render in notebooks"""
-        return _notebooks_remove_ipy_widgets.get()
-
-    @_notebooks_remove_ipy_widgets.setter
-    def _notebooks_remove_ipy_widgets(self, value: bool) -> None:
-
-        _notebooks_remove_ipy_widgets.set(value)
-
 
 context = Context()
```

## datarobotx/common/logging.py

```diff
@@ -10,37 +10,38 @@
 #
 # Released under the terms of DataRobot Tool and Utility Agreement.
 from __future__ import annotations
 
 import asyncio
 import contextvars
 import logging
+import os
 import re
 import textwrap
 from typing import cast, Optional, Tuple, Union
 
 from termcolor import colored
 import tqdm as tqdm_typing
 from tqdm.notebook import tqdm_notebook, TqdmHBox  # type: ignore[attr-defined]
 from tqdm.std import tqdm as std_tqdm
 
-from datarobotx.common.config import context, is_notebook_env
+from datarobotx.common.config import is_notebook_env
 
 logger = logging.getLogger("drx")
 logger.setLevel(logging.INFO)
 # Context variable for the jupyter widget logging messages  + progress bars should be directed toward
 logging_output_widget: contextvars.ContextVar = contextvars.ContextVar(  # type: ignore[type-arg]
     "logging_output_widget"
 )
 
 
 def is_widgets_nb_env() -> bool:
     """Detect if this is an interactive notebook with ipywidgets installed"""
 
-    if not is_notebook_env() or context._notebooks_remove_ipy_widgets:
+    if not is_notebook_env() or "DATAROBOT_NOTEBOOK_IMAGE" in os.environ:
         return False
     try:
         import ipywidgets  # noqa: F401  pylint: disable=import-outside-toplevel, unused-import
 
         return True
     except ImportError:
         pass
```

## datarobotx/common/utils.py

```diff
@@ -731,7 +731,37 @@
 async def log_when_complete(
     it: AsyncIterator[Any], msg: str, extra: Optional[Dict[str, Any]] = None
 ) -> AsyncIterator[Any]:
     """Wrapper for async iterator that logs a message when iterator is exhausted"""
     async for item in it:
         yield item
     logger.info(msg, extra=extra)
+
+
+TIME_UNIT_MAPPING: Dict[str, Dict[str, Any]] = {
+    # FEAR supported time units: Thanks Yemi!
+    "to_seconds": {
+        "MILLISECOND": 0.001,
+        "SECOND": 1,
+        "MINUTE": int(pd.Timedelta("1 minutes").total_seconds()),
+        "HOUR": int(pd.Timedelta("1 hours").total_seconds()),
+        "DAY": int(pd.Timedelta("1 days").total_seconds()),
+        "WEEK": int(pd.Timedelta("7 days").total_seconds()),
+        "MONTH": int(pd.Timedelta("365 days").total_seconds() / 12),
+        "QUARTER": int(pd.Timedelta("365 days").total_seconds() / 4),
+        "YEAR": int(pd.Timedelta("365 days").total_seconds()),
+        "ROW": 1,
+    },
+    # https://pandas.pydata.org/docs/user_guide/timeseries.html#timeseries-offset-aliases
+    "to_pandas_offset": {
+        "MILLISECOND": "ms",
+        "SECOND": "S",
+        "MINUTE": "min",
+        "HOUR": "H",
+        "DAY": "D",
+        "WEEK": "W",
+        # S = start i.e. first day of month
+        "MONTH": "MS",
+        "QUARTER": "QS",
+        "YEAR": "YS",
+    },
+}
```

## datarobotx/models/autots.py

```diff
@@ -7,14 +7,15 @@
 #
 # This is proprietary source code of DataRobot, Inc. and its
 # affiliates.
 #
 # Released under the terms of DataRobot Tool and Utility Agreement.
 from __future__ import annotations
 
+import datetime as dt
 import logging
 from typing import Any, Dict, List, Optional, Tuple, Union
 
 import pandas as pd
 
 from datarobotx.common import utils
 from datarobotx.models.autopilot import AutopilotModel
@@ -102,40 +103,44 @@
         return dict(params)
 
     def fit(  # type: ignore[no-untyped-def]
         self,
         X: Union[pd.DataFrame, str],
         datetime_partition_column: str,
         target: Optional[str] = None,
-        multiseries_id_columns: Optional[Union[str, List[str]]] = None,
+        kia_columns: Optional[List[str]] = None,
+        multiseries_id_columns: Optional[str] = None,
         segmentation_id_column: Optional[str] = None,
-        **kwargs,
+        **kwargs: Any,
     ) -> AutoTSModel:
         """
         Fit time-series challenger models using DataRobot
 
         Automatically engineers temporally lagged features and establishes
         time-series champion models across a forecast horizon of interest.
 
         Parameters
         ----------
-        X : pandas.DataFrame
+        X : pandas.DataFrame or str
             Training dataset for challenger models.
             If str, can be AI catalog dataset id or name (if unambiguous)
         target : str, default=None
             Column name from the dataset to be used as the target variable.
             If None, TS anomaly detection will be executed.
         datetime_partition_column : str
             Column name from the dataset containing the primary date/time feature to
             be used in partitioning, feature engineering, and establishing forecast
             horizons
         multiseries_id_columns : str or list of str, optional
             Column name from the dataset containing a series identifier for each row.
             If specified, DataRobot will treat this as a multiseries problem. Presently
             only a single series id column is supported.
+        kia_columns : list of str, optional
+            List of column names for features that are known at prediction time.
+            If not empty, DataRobot will require these features in prediction dataset.
         segmentation_id_column: str, optional
             Column name from the dataset containing a segmentation identifier for each row.
             If specified, DataRobot will perform segmented modeling to break the problem
             into multiple projects.
         **kwargs :
             Additional optional fit-time parameters to pass to DataRobot i.e. 'weights'
 
@@ -146,27 +151,128 @@
             also includes detailed examples of usage.
         """
         utils.create_task_new_thread(
             self._fit(
                 X,
                 target=target,
                 datetime_partition_column=datetime_partition_column,
+                kia_columns=kia_columns,
                 multiseries_id_columns=multiseries_id_columns,
                 segmentation_id_column=segmentation_id_column,
                 **kwargs,
             )
         )
         return self
 
     def _set_fit_params(self, **kwargs) -> None:  # type: ignore[no-untyped-def]
         """Handle time-series specific fit-time parameters"""
         if "multiseries_id_columns" in kwargs and isinstance(kwargs["multiseries_id_columns"], str):
             kwargs["multiseries_id_columns"] = [kwargs["multiseries_id_columns"]]
 
+        kia_columns = kwargs.pop("kia_columns")
+        if kia_columns is not None:
+            kwargs["feature_settings"] = [
+                {"featureName": i, "knownInAdvance": True} for i in kia_columns
+            ]
+
         segmentation_id_column = kwargs.pop("segmentation_id_column")
         if segmentation_id_column is not None:
             logger.info(
                 "Segmentation values provided. Drx cannot make predictions until "
                 "Autopilot is finished. These projects can take a while.."
             )
             self._segmentation_id_column = [segmentation_id_column]
         return super()._set_fit_params(**kwargs)
+
+    def predict(
+        self,
+        X: Union[pd.DataFrame, str],
+        wait_for_autopilot: bool = False,
+        as_of: Optional[Union[str, dt.datetime]] = None,
+        for_dates: Optional[
+            Union[str, dt.datetime, Tuple[str, str], Tuple[dt.datetime, dt.datetime]]
+        ] = None,
+        **kwargs: Any,
+    ) -> pd.DataFrame:
+        """
+        Make predictions for a time-series dataset
+
+        Parameters
+        ----------
+        X : pandas.DataFrame or str
+            Dataset for which predictions are to be made.
+            If str, can be AI catalog dataset id
+        wait_for_autopilot : bool, default=False
+        as_of : str or datetime, optional
+            Date/time to use as the forecast point for predictions.
+            If not specified, the latest date/time in the dataset will be used.
+            Note that dates passed in are parsed using pd.to_datetime.
+        for_dates : str or tuple of str or datetime, optional
+            Dates to return predictions for. If a single date is specified, a single
+            prediction will be returned for that date. If a tuple of dates is specified,
+            a prediction will be returned for each date in the range.
+            Note that dates passed in are parsed using pd.to_datetime.
+        **kwargs :
+            Additional optional predict-time parameters to pass to DataRobot
+            Examples: 'forecast_point', 'predictions_start_date', 'predictions_end_date',
+            'relax_known_in_advance_features_check'
+        Returns
+        -------
+        FutureDataFrame
+            Resulting predictions; probabilities for each label are contained in the
+            column 'class_{label}'; returned immediately, updated automatically
+            when results are completed.
+        """
+        return super().predict(
+            X,
+            wait_for_autopilot,
+            as_of=as_of,
+            for_dates=for_dates,
+            **kwargs,
+        )
+
+    def predict_proba(
+        self,
+        X: Union[pd.DataFrame, str],
+        wait_for_autopilot: bool = False,
+        as_of: Optional[Union[str, dt.datetime]] = None,
+        for_dates: Optional[
+            Union[str, dt.datetime, Tuple[str, str], Tuple[dt.datetime, dt.datetime]]
+        ] = None,
+        **kwargs: Any,
+    ) -> pd.DataFrame:
+        """
+        Calculate class probabilities using the present champion
+
+        Parameters
+        ----------
+        X : pandas.DataFrame or str
+            Dataset for which predictions are to be made.
+            If str, can be AI catalog dataset id
+        wait_for_autopilot : bool, default=False
+        as_of : str, optional
+            Date/time to use as the forecast point for predictions.
+            If not specified, the latest date/time in the dataset will be used.
+            Note that dates passed in are parsed using pd.to_datetime
+        for_dates : str or tuple of str, optional
+            Dates to return predictions for. If a single date is specified, a single
+            prediction will be returned for that date. If a tuple of dates is specified,
+            a prediction will be returned for each date in the range.
+            Note that dates passed in are parsed using pd.to_datetime
+        **kwargs :
+            Additional optional predict-time parameters to pass to DataRobot
+            Examples: 'forecast_point', 'predictions_start_date', 'predictions_end_date',
+            'relax_known_in_advance_features_check'
+        Returns
+        -------
+        FutureDataFrame
+            Resulting predictions; probabilities for each label are contained in the
+            column 'class_{label}'; returned immediately, updated automatically
+            when results are completed.
+        """
+        return super().predict_proba(
+            X,
+            wait_for_autopilot,
+            as_of=as_of,
+            for_dates=for_dates,
+            **kwargs,
+        )
```

## datarobotx/models/deployment.py

```diff
@@ -9,24 +9,26 @@
 # affiliates.
 #
 # Released under the terms of DataRobot Tool and Utility Agreement.
 from __future__ import annotations
 
 import asyncio
 from dataclasses import dataclass
+import datetime as dt
 import logging
 import re
 import time
-from typing import Any, Dict, List, Optional, Union
+from typing import Any, Dict, List, Optional, Tuple, Union
 
 import pandas as pd
 
 import datarobot
+from datarobot.utils import to_api
 import datarobotx.client.deployments as deploy_client
-from datarobotx.common import utils
+from datarobotx.common import ts_helpers, utils
 from datarobotx.common.config import context
 from datarobotx.models import share
 
 logger = logging.getLogger("drx")
 
 
 @utils.hidden_instance_classmethods
@@ -89,14 +91,19 @@
         return Deployment(deployment_id=deployment_id)
 
     def predict(
         self,
         X: pd.DataFrame,
         batch_mode: bool = False,
         max_explanations: Union[int, str, None] = None,
+        as_of: Optional[Union[str, dt.datetime]] = None,
+        for_dates: Optional[
+            Union[str, dt.datetime, Tuple[str, str], Tuple[dt.datetime, dt.datetime]]
+        ] = None,
+        **kwargs: Any,
     ) -> pd.DataFrame:
         """
         Make predictions on X asynchronously using the deployment
 
         Returns empty DataFrame which will be updated with results when complete
 
         Parameters
@@ -105,25 +112,51 @@
             Data to make predictions on
         batch_mode: bool (default=False)
             If True, use batch mode for predictions
         max_explanations: int or 'all' (default=None)
             Number of explanations to return for each prediction.
             Note that 'all' is supported for deployments using SHAP models
             only.
+        as_of: str (default=None)
+            Applies to time series only. Forecast point to use for predictions.
+            If not provided on a forecast, the latest forecast point will be used.
+            Note that dates passed in are parsed using pd.to_datetime.
+        for_dates: str or tuple of str (default=None)
+            Applies to time series only. Date(s) to return predictions for.
+            If a single date is specified, a single prediction will be returned
+            for that date. If a tuple of dates is specified,
+            a prediction will be returned for each date in the range.
+            Note that dates passed in are parsed using pd.to_datetime.
+        **kwargs :
+            Additional optional predict-time parameters to pass to DataRobot
+            Examples: 'forecast_point', 'predictions_start_date', 'predictions_end_date',
+            'relax_known_in_advance_features_check'
 
         """
-        out = self._dispatch_predict(X, batch_mode, max_explanations=max_explanations)
+        out = self._dispatch_predict(
+            X,
+            batch_mode,
+            max_explanations=max_explanations,
+            as_of=as_of,
+            for_dates=for_dates,
+            **kwargs,
+        )
         assert isinstance(out, pd.DataFrame)
         return out
 
     def predict_proba(
         self,
         X: pd.DataFrame,
         batch_mode: bool = False,
         max_explanations: Union[int, str, None] = None,
+        as_of: Optional[Union[str, dt.datetime]] = None,
+        for_dates: Optional[
+            Union[str, dt.datetime, Tuple[str, str], Tuple[dt.datetime, dt.datetime]]
+        ] = None,
+        **kwargs: Any,
     ) -> pd.DataFrame:
         """
         Calculate class probabilities on X asynchronously using the deployment
 
         Returns empty DataFrame which will be updated with results when complete
 
         Parameters
@@ -132,18 +165,37 @@
             Data to make predictions on
         batch_mode: bool (default=False)
             If True, use batch mode for predictions
         max_explanations: int or 'all' (default=None)
             Number of explanations to return for each prediction.
             Note that 'all' is supported for deployments using SHAP models
             only.
-
+        as_of: str (default=None)
+            Applies to time series only. Forecast point to use for predictions.
+            If not provided on a forecast, the latest forecast point will be used.
+            Note that dates passed in are parsed using pd.to_datetime.
+        for_dates: str or tuple of str (default=None)
+            Applies to time series only. Date(s) to return predictions for.
+            If a single date is specified, a single prediction will be returned
+            for that date. If a tuple of dates is specified,
+            a prediction will be returned for each date in the range.
+            Note that dates passed in are parsed using pd.to_datetime.
+        **kwargs :
+            Additional optional predict-time parameters to pass to DataRobot
+            Examples: 'forecast_point', 'predictions_start_date', 'predictions_end_date',
+            'relax_known_in_advance_features_check'
         """
         out = self._dispatch_predict(
-            X, batch_mode, class_probabilities=True, max_explanations=max_explanations
+            X,
+            batch_mode=batch_mode,
+            max_explanations=max_explanations,
+            class_probabilities=True,
+            as_of=as_of,
+            for_dates=for_dates,
+            **kwargs,
         )
         assert isinstance(out, pd.DataFrame)
         return out
 
     def predict_unstructured(self, X: Dict[str, Any]) -> Dict[str, Any]:
         """
         Make predictions with data asynchronously using the deployment
@@ -163,14 +215,19 @@
     def _dispatch_predict(
         self,
         X: Union[pd.DataFrame, Dict[str, Any]],
         batch_mode: bool,
         class_probabilities: bool = False,
         max_explanations: Union[int, str, None] = None,
         unstructured: bool = False,
+        as_of: Optional[Union[str, dt.datetime]] = None,
+        for_dates: Optional[
+            Union[str, dt.datetime, Tuple[str, str], Tuple[dt.datetime, dt.datetime]]
+        ] = None,
+        **kwargs: Any,
     ) -> Union[pd.DataFrame, Dict[str, Any]]:
         """Private method for dispatching predictions work
 
         Behavior depends on requested predictions type (structured vs. unstructured)
         and whether this deployment object has been initialized
         """
 
@@ -187,14 +244,17 @@
         future = utils.create_task_new_thread(
             self._predict(
                 X,
                 batch_mode=batch_mode,
                 class_probabilities=class_probabilities,
                 max_explanations=max_explanations,
                 unstructured=unstructured,
+                as_of=as_of,
+                for_dates=for_dates,
+                **kwargs,
             )
         )
 
         if not unstructured:
             result: Union[pd.DataFrame, Dict[str, Any]] = utils.FutureDataFrame(future=future)
         else:
             result = utils.FutureDict(future=future)
@@ -203,33 +263,69 @@
     async def _predict(
         self,
         X: Union[pd.DataFrame, Dict[str, Any]],
         batch_mode: bool,
         class_probabilities: bool = False,
         max_explanations: Union[int, str, None] = None,
         unstructured: bool = False,
+        **kwargs: Any,
     ) -> Union[pd.DataFrame, Dict[str, Any]]:
+
         deploy_info = await self._validate_predict_args(
             class_probabilities,
             max_explanations=max_explanations,
         )
+        uses_ts_helpers = (
+            deploy_info.model_kind.isTimeSeries
+            and not deploy_info.model_kind.isClustering
+            and ts_helpers._has_ts_helper_args(**kwargs)
+        )
+
+        if uses_ts_helpers:
+            (
+                X,
+                time_series_parameters,
+                ts_project_settings,
+            ) = await ts_helpers.prepare_prediction_data(
+                str(deploy_info.model_kind.projectId),
+                X,
+                as_of=kwargs.get("as_of"),
+                for_dates=kwargs.get("for_dates"),
+            )
+            if batch_mode:
+                time_series_parameters["relaxKnownInAdvanceFeaturesCheck"] = True
+
+        else:
+            ts_api_arguments = [
+                "predictions_start_date",
+                "predictions_end_date",
+                "forecast_point",
+                "relax_known_in_advance_features_check",
+            ]
+
+            time_series_parameters = to_api(
+                {key: kwargs[key] for key in ts_api_arguments if key in kwargs}
+            )
+
         if not unstructured:
             if not batch_mode:
                 preds_df = await deploy_client.post_predictions(
                     did=self._deployment_id,  # type: ignore[arg-type]
                     dr_key=deploy_info.dr_key,
                     pred_server_endpoint=deploy_info.endpoint,
                     payload=utils.prepare_df_upload(X),
                     max_explanations=max_explanations,  # type: ignore[arg-type]
+                    ts_params=time_series_parameters,
                 )
             else:
                 pred_url = await deploy_client.post_batch_predictions(
                     did=self._deployment_id,  # type: ignore[arg-type]
                     payload=utils.prepare_df_upload(X),
                     max_explanations=max_explanations,  # type: ignore[arg-type]
+                    ts_params=time_series_parameters,
                 )
                 preds_df = await deploy_client.await_batch_job_completion(pred_url)
 
             result = PredictionFormatter(
                 preds=preds_df,
                 model_kind=deploy_info.model_kind,
                 class_probabilities=class_probabilities,
@@ -238,14 +334,18 @@
         else:
             result = await deploy_client.post_predictions_unstructured(
                 did=self._deployment_id,  # type: ignore[arg-type]
                 dr_key=deploy_info.dr_key,
                 pred_server_endpoint=deploy_info.endpoint,
                 data=X,
             )
+        if uses_ts_helpers:
+            result = ts_helpers.post_process_predictions(
+                result, ts_project_settings, for_dates=kwargs.get("for_dates")
+            )
 
         logger.info("Predictions complete", extra={"is_header": True})
         return result
 
     async def _validate_predict_args(
         self, class_probabilities: bool, max_explanations: Union[int, str, None]
     ) -> DeploymentInfo:
@@ -630,14 +730,15 @@
     isMultilabel: bool = False
     isMultiClass: bool = False
     isRegression: bool = False
     isBinary: bool = False
     seriesId: Optional[str] = None
     timestampCol: Optional[str] = None
     targetName: Optional[str] = None
+    projectId: Optional[str] = None
 
     @staticmethod
     def infer_model_kind(
         settings_json: Dict[str, Any], deployment_json: Dict[str, Any]
     ) -> ModelKind:
         """
         Infer DataRobot deployed model capabilities
@@ -661,14 +762,15 @@
         Notes
         -----
         Due to limitations of the API, returned predictions may also need to be
         inspected to correctly infer all capabilities. See
         `confirm_model_kind_from_results`
 
         """
+        projectId = deployment_json["model"]["projectId"]
         isAnomalyDetectionModel = False
         isCombinedModel = False
         isDecisionFlow = False
         isFeatureDiscovery = False
         isMultiseries = False
         isTimeSeries = False
         isUnsupervisedLearning = deployment_json["model"]["unsupervisedMode"]
@@ -710,14 +812,15 @@
         else:
             isMultiClass = False
         # are we binary?
         if deployment_json["model"]["targetType"] == "Binary":
             isBinary = True
 
         return ModelKind(
+            projectId=projectId,
             isAnomalyDetectionModel=isAnomalyDetectionModel,
             isCombinedModel=isCombinedModel,
             isDecisionFlow=isDecisionFlow,
             isFeatureDiscovery=isFeatureDiscovery,
             isMultiseries=isMultiseries,
             isMultilabel=isMultilabel,
             isTimeSeries=isTimeSeries,
```

## datarobotx/models/evaluation.py

```diff
@@ -105,15 +105,15 @@
     Upload external dataset if needed
     """
     if isinstance(evaluation_data, str):
         ds_json = await proj_client.get_prediction_dataset(model._project_id, evaluation_data)  # type: ignore[arg-type]
         if "id" in ds_json:
             return cast(str, ds_json["id"])
     # Runs if evaluation data is a dataframe or an ai catalog id
-    ds_json = await model._create_pred_dataset(evaluation_data)
+    ds_json = await model._create_pred_dataset(model._project_id, evaluation_data)  # type: ignore[arg-type]
     return cast(str, ds_json["id"])
 
 
 def import_parametric_model(model: AutoMLModel, model_formula: str) -> Model:
     """Import a linear model onto the DataRobot leaderboard
 
     bp_base = find_smallest_non_additive_eureqa_blueprint()
```

## datarobotx/models/model.py

```diff
@@ -19,18 +19,19 @@
 import re
 import time
 from typing import Any, Dict, List, Optional, TYPE_CHECKING, Union
 
 import numpy as np
 import pandas as pd
 
+from datarobot.utils import to_api
 import datarobotx.client.datasets as dataset_client
 import datarobotx.client.deployments as deploy_client
 import datarobotx.client.projects as proj_client
-from datarobotx.common import utils
+from datarobotx.common import ts_helpers, utils
 from datarobotx.common.config import context
 from datarobotx.common.utils import FutureDataFrame
 from datarobotx.models import share
 from datarobotx.models.deployment import Deployment
 from datarobotx.viz.leaderboard import LeaderboardFormatter
 from datarobotx.viz.modelcard import ModelCardFormatter
 from datarobotx.viz.viz import designated_widget_handler
@@ -120,15 +121,15 @@
             raise RuntimeError(
                 "Cannot to retrieve a datarobot.Project from an uninitialized model."
             )
         import datarobot
 
         return datarobot.Project.get(self._project_id)
 
-    def predict(self, X: Union[pd.DataFrame, str]) -> FutureDataFrame:
+    def predict(self, X: Union[pd.DataFrame, str], **kwargs: Any) -> FutureDataFrame:
         """
         Make batch predictions using the model
 
         Predictions are calculated asynchronously - returns immediately but
         reinitializes the returned DataFrame with data once predictions are
         completed.
 
@@ -136,103 +137,138 @@
         workers. For real-time predictions, first deploy the model.
 
         Parameters
         ----------
         X : pandas.DataFrame or str
             Dataset to be scored - target column can be included or omitted.
             If str, can be AI catalog dataset id or name (if unambiguous)
+        **kwargs : Any
+            Other key word arguments to pass to the _predict function
 
         Returns
         -------
         FutureDataFrame
             Resulting predictions (contained in the column 'predictions')
             Returned immediately, updated automatically when results are
             completed. If attribute access is attempted, will block until results
             are completed.
 
         """
-        future = utils.create_task_new_thread(self._predict(X))
+        future = utils.create_task_new_thread(self._predict(X, **kwargs))
         return utils.FutureDataFrame(future=future)
 
-    def predict_proba(self, X: Union[pd.DataFrame, str]) -> FutureDataFrame:
+    def predict_proba(self, X: Union[pd.DataFrame, str], **kwargs: Any) -> FutureDataFrame:
         """
         Calculate class probabilities using the model
 
         Only available for classifier models.
 
         Parameters
         ----------
         X : pandas.DataFrame or str
             Dataset to compute class probabilities on; target column can be included
             or omitted. If str, can be AI catalog dataset id or name (if unambiguous)
+        **kwargs : Any
+            Other key word arguments to pass to the _predict function
 
         Returns
         -------
         FutureDataFrame
             Resulting predictions; probabilities for each label are contained in the
             column 'class_{label}'; returned immediately, updated automatically
             when results are completed. If attribute access is attempted, will block
             until results are completed.
 
         See Also
         --------
         predict
-
         """
-        future = utils.create_task_new_thread(self._predict(X, class_probabilities=True))
+        future = utils.create_task_new_thread(self._predict(X, class_probabilities=True, **kwargs))
         return utils.FutureDataFrame(future=future)
 
     async def _predict(
-        self,
-        X: Union[pd.DataFrame, str],
-        class_probabilities: bool = False,
-    ) -> pd.DataFrame:
+        self, X: Union[pd.DataFrame, str], class_probabilities: bool = False, **kwargs: Any
+    ) -> None:
         """Orchestrate training model batch predictions."""
         await self._validate_predict_args(class_probabilities)
+        project_id = str(self._project_id)
+        project_data = await proj_client.get_project(project_id)
+        uses_ts_helpers = (
+            project_data["partition"]["useTimeSeries"]
+            and project_data["unsupervisedType"] != "clustering"
+            and ts_helpers._has_ts_helper_args(**kwargs)
+        )
+
+        json: Dict[str, Any] = {"modelId": self._model_id}
+
+        if uses_ts_helpers:
+            (
+                X,
+                time_series_parameters,
+                ts_project_settings,
+            ) = await ts_helpers.prepare_prediction_data(project_id, X, **kwargs)
+        else:
+            ts_api_arguments = [
+                "predictions_start_date",
+                "predictions_end_date",
+                "forecast_point",
+            ]
+            time_series_parameters = to_api(
+                {key: kwargs[key] for key in ts_api_arguments if key in kwargs}
+            )
+        json.update(time_series_parameters)
 
-        prediction_ds = await self._create_pred_dataset(X)
-
-        predictions_id = await proj_client.post_predictions(
-            pid=self._project_id,  # type: ignore[arg-type]
-            model_id=self._model_id,  # type: ignore[arg-type]
-            ds_id=prediction_ds["id"],
-            date_range=prediction_ds.get("forecastPointRange"),
+        prediction_ds = await self._create_pred_dataset(
+            project_id,
+            X,
+            relax_kia_check=uses_ts_helpers
+            or kwargs.get("relax_known_in_advance_features_check", False),
         )
 
+        json["datasetId"] = prediction_ds["id"]
+        predictions_id = await proj_client.post_predictions(pid=project_id, json=json)
+
         assert self._project_id is not None
         df = await proj_client.get_predictions(
-            pid=self._project_id,
+            pid=project_id,
             predictions_id=predictions_id,
         )
 
         df = await self._format_predictions(df, class_probabilities)
+
+        if uses_ts_helpers:
+            df = ts_helpers.post_process_predictions(
+                df, ts_project_settings, for_dates=kwargs.get("for_dates")
+            )
         logger.info("Predictions complete", extra={"is_header": True})
         return df
 
-    async def _create_pred_dataset(self, X: Union[pd.DataFrame, str]) -> Dict[str, Any]:
+    @staticmethod
+    async def _create_pred_dataset(
+        pid: str, X: Union[pd.DataFrame, str], relax_kia_check: bool = False
+    ) -> Dict[str, Any]:
         """Create a prediction dataset server-side for DR to make predictions"""
         if isinstance(X, pd.DataFrame):
             prediction_ds = await proj_client.post_prediction_datasets_file_uploads(
-                pid=self._project_id,  # type: ignore[arg-type]
+                pid=pid,  # type: ignore[arg-type]
                 payload=utils.prepare_df_upload(X),
+                relax_kia_check=relax_kia_check,
             )
         elif isinstance(X, str):
             dataset_id = await dataset_client.resolve_dataset_id(X)
             prediction_ds = await proj_client.post_prediction_datasets_dataset_uploads(
-                pid=self._project_id,  # type: ignore[arg-type]
-                dataset_id=dataset_id,
+                pid=pid, dataset_id=dataset_id, relax_kia_check=relax_kia_check
             )
         else:
             raise TypeError(
                 "Provided data to be scored must be a pandas.DataFrame "
                 + "or the DataRobot dataset id or name."
             )
-        return prediction_ds
 
-    # async def _post_external_scores(self, prediction)
+        return prediction_ds
 
     async def _format_predictions(
         self, df: pd.DataFrame, class_probabilities: bool
     ) -> pd.DataFrame:
         """Format dataframe returned by DataRobot pre-deployment predictions route"""
         project_json = await proj_client.get_project(pid=self._project_id)  # type: ignore[arg-type]
 
@@ -313,16 +349,16 @@
         name : str, optional, default=None
             Name for the deployment. If None, a name will be generated
 
         Returns
         -------
         Deployment
             Resulting ML Ops deployment
-
         """
+
         if self._project_id is None or self._model_id is None:
             raise RuntimeError("Cannot deploy an uninitialized model. ")
 
         deployment = Deployment()
         utils.create_task_new_thread(self._deploy(deployment, name=name))
         return deployment
 
@@ -489,15 +525,15 @@
         if self._project_id is None:
             raise RuntimeError("Cannot retrieve a datarobot.Project from an uninitialized model.")
         import datarobot
 
         return datarobot.Project.get(self._project_id)
 
     def predict(
-        self, X: pd.DataFrame, wait_for_autopilot: Optional[bool] = False
+        self, X: pd.DataFrame, wait_for_autopilot: bool = False, **kwargs: Any
     ) -> FutureDataFrame:
         """
         Make batch predictions using the present champion
 
         Predictions are calculated asynchronously - returns immediately but
         reinitializes the returned DataFrame with data once predictions are
         completed.
@@ -508,78 +544,85 @@
         Parameters
         ----------
         X : pandas.DataFrame
             Dataset to be scored - target column can be included or omitted
         wait_for_autopilot : bool, optional, default=False
             If True, wait for autopilot to complete before making predictions
             In non-notebook environments, fit() will always block until complete
+        **kwargs : Any
+            Other key word arguments to pass to the _predict function
 
         Returns
         -------
         FutureDataFrame
             Resulting predictions (contained in the column 'predictions')
             Returned immediately, updated automatically when results are
             completed.
 
         """
-        return self._predict(X, wait_for_autopilot=wait_for_autopilot)
+        return self._predict(X, wait_for_autopilot=wait_for_autopilot, **kwargs)
 
     def predict_proba(
-        self, X: pd.DataFrame, wait_for_autopilot: Optional[bool] = False
+        self, X: pd.DataFrame, wait_for_autopilot: bool = False, **kwargs: Any
     ) -> FutureDataFrame:
         """
         Calculate class probabilities using the present champion
 
         Only available for classifier and clustering models.
 
         Parameters
         ----------
         X : pandas.DataFrame
             Dataset to compute class probabilities on; target column can be included
             or omitted
         wait_for_autopilot : bool, optional, default=False
             If True, wait for autopilot to complete before making predictions
             In non-notebook environments, fit() will always block until complete
+        **kwargs : Any
+            Other key word arguments to pass to the _predict function
 
         Returns
         -------
         FutureDataFrame
             Resulting predictions; probabilities for each label are contained in the
             column 'class_{label}'; returned immediately, updated automatically
             when results are completed.
 
         See Also
         --------
         predict
 
         """
 
-        return self._predict(X, class_probabilities=True, wait_for_autopilot=wait_for_autopilot)
+        return self._predict(
+            X, class_probabilities=True, wait_for_autopilot=wait_for_autopilot, **kwargs
+        )
 
     def _predict(
         self,
-        X: Any,
-        class_probabilities: Optional[bool] = False,
-        wait_for_autopilot: Optional[bool] = False,
-    ) -> utils.FutureDataFrame:
+        X: Union[pd.DataFrame, str],
+        class_probabilities: bool = False,
+        wait_for_autopilot: bool = False,
+        **kwargs: Any,
+    ) -> FutureDataFrame:
         """Private method for making predictions with predict() or predict_proba()"""
         if self._best_model is None and not self._fitting_underway:
             raise RuntimeError("fit() must be called before making predictions")
 
         if wait_for_autopilot:
             logger.info("Waiting for autopilot to complete...", extra={"is_header": True})
             self._wait()
 
         elif self._best_model is None:
             logger.info("Waiting for a trained model...", extra={"is_header": True})
             while self._best_model is None:
                 time.sleep(context._concurrency_poll_interval)
 
         future = utils.create_task_new_thread(
-            self._best_model._predict(X, class_probabilities=class_probabilities)  # type: ignore[union-attr,arg-type]
+            self._best_model._predict(X, class_probabilities=class_probabilities, **kwargs)  # type: ignore[union-attr]
         )
 
         return utils.FutureDataFrame(future=future)
 
     def deploy(
         self, wait_for_autopilot: Optional[bool] = False, name: Optional[str] = None
     ) -> Deployment:
@@ -651,14 +694,15 @@
         Render a leaderboard for widget-enabled ipython environments
 
         Called by ipython when last expression in a cell is not an assignment operation
         and the expression evaluates to an instanceof this object.
 
         Dynamically setup and teardown a logging handler for rendering the leaderboard.
         """
+
         with designated_widget_handler(
             formatter=LeaderboardFormatter(attr="model_operator", as_html=True),
             filter_on=lambda x: int(getattr(x, "model_operator", 0) is self),
             remove_when=(lambda: not self._fitting_underway) if self._fitting_underway else None,
         ):
             logger.info(
                 "Handling _ipython_display_() call for ModelOperator",
```

## datarobotx/viz/leaderboard.py

```diff
@@ -57,15 +57,14 @@
             models_json: List[Any]
             rec_model_json: Dict[str, Any]
             proj_json, models_json, rec_model_json = await asyncio.gather(
                 proj_client.get_project(model._project_id),
                 proj_client.get_models(model._project_id, params={"orderBy": "-metric"}),
                 proj_client.get_recommended_model(model._project_id),
             )
-            # TODO: Marshall resolve ordering issues
             record.proj_json = proj_json
             models_list = []
             for i in model._leaderboard[:5]:
                 for j in models_json:
                     if j["id"] == i:
                         models_list.append(j)
                         break
```

## Comparing `datarobotx-0.1.4.dist-info/METADATA` & `datarobotx-0.1.5.dist-info/METADATA`

 * *Files 4% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 00000000: 4d65 7461 6461 7461 2d56 6572 7369 6f6e  Metadata-Version
 00000010: 3a20 322e 310a 4e61 6d65 3a20 6461 7461  : 2.1.Name: data
 00000020: 726f 626f 7478 0a56 6572 7369 6f6e 3a20  robotx.Version: 
-00000030: 302e 312e 340a 5375 6d6d 6172 793a 2044  0.1.4.Summary: D
+00000030: 302e 312e 350a 5375 6d6d 6172 793a 2044  0.1.5.Summary: D
 00000040: 6174 6152 6f62 6f74 5820 6973 2061 2063  ataRobotX is a c
 00000050: 6f6c 6c65 6374 696f 6e20 6f66 2044 6174  ollection of Dat
 00000060: 6152 6f62 6f74 2065 7874 656e 7369 6f6e  aRobot extension
 00000070: 730a 486f 6d65 2d70 6167 653a 2068 7474  s.Home-page: htt
 00000080: 7073 3a2f 2f64 6174 6172 6f62 6f74 2e67  ps://datarobot.g
 00000090: 6974 6875 622e 696f 2f64 7278 0a41 7574  ithub.io/drx.Aut
 000000a0: 686f 723a 2044 6174 6152 6f62 6f74 0a41  hor: DataRobot.A
@@ -67,230 +67,268 @@
 00000420: 6972 6573 2d44 6973 743a 206e 616d 6573  ires-Dist: names
 00000430: 2d67 656e 6572 6174 6f72 0a52 6571 7569  -generator.Requi
 00000440: 7265 732d 4469 7374 3a20 7061 6e64 6173  res-Dist: pandas
 00000450: 0a52 6571 7569 7265 732d 4469 7374 3a20  .Requires-Dist: 
 00000460: 5079 5961 6d6c 0a52 6571 7569 7265 732d  PyYaml.Requires-
 00000470: 4469 7374 3a20 7365 7475 7074 6f6f 6c73  Dist: setuptools
 00000480: 0a52 6571 7569 7265 732d 4469 7374 3a20  .Requires-Dist: 
-00000490: 7465 726d 636f 6c6f 720a 5265 7175 6972  termcolor.Requir
-000004a0: 6573 2d44 6973 743a 2074 7164 6d0a 5072  es-Dist: tqdm.Pr
-000004b0: 6f76 6964 6573 2d45 7874 7261 3a20 6465  ovides-Extra: de
-000004c0: 706c 6f79 0a52 6571 7569 7265 732d 4469  ploy.Requires-Di
-000004d0: 7374 3a20 636c 6f75 6470 6963 6b6c 6520  st: cloudpickle 
-000004e0: 3b20 6578 7472 6120 3d3d 2027 6465 706c  ; extra == 'depl
-000004f0: 6f79 270a 5265 7175 6972 6573 2d44 6973  oy'.Requires-Dis
-00000500: 743a 2074 7261 6e73 666f 726d 6572 7320  t: transformers 
-00000510: 3b20 6578 7472 6120 3d3d 2027 6465 706c  ; extra == 'depl
-00000520: 6f79 270a 5265 7175 6972 6573 2d44 6973  oy'.Requires-Dis
-00000530: 743a 2073 6369 6b69 742d 6c65 6172 6e20  t: scikit-learn 
-00000540: 3b20 6578 7472 6120 3d3d 2027 6465 706c  ; extra == 'depl
-00000550: 6f79 270a 5072 6f76 6964 6573 2d45 7874  oy'.Provides-Ext
-00000560: 7261 3a20 6465 760a 5265 7175 6972 6573  ra: dev.Requires
-00000570: 2d44 6973 743a 2066 6c61 6b65 3820 283d  -Dist: flake8 (=
-00000580: 3d35 2e30 2e34 2920 3b20 6578 7472 6120  =5.0.4) ; extra 
-00000590: 3d3d 2027 6465 7627 0a52 6571 7569 7265  == 'dev'.Require
-000005a0: 732d 4469 7374 3a20 7079 6c69 6e74 2028  s-Dist: pylint (
-000005b0: 3d3d 322e 3135 2e30 2920 3b20 6578 7472  ==2.15.0) ; extr
-000005c0: 6120 3d3d 2027 6465 7627 0a52 6571 7569  a == 'dev'.Requi
-000005d0: 7265 732d 4469 7374 3a20 626c 6163 6b20  res-Dist: black 
-000005e0: 283d 3d32 322e 382e 3029 203b 2065 7874  (==22.8.0) ; ext
-000005f0: 7261 203d 3d20 2764 6576 270a 5265 7175  ra == 'dev'.Requ
-00000600: 6972 6573 2d44 6973 743a 2069 736f 7274  ires-Dist: isort
-00000610: 2028 3d3d 352e 3130 2e31 2920 3b20 6578   (==5.10.1) ; ex
-00000620: 7472 6120 3d3d 2027 6465 7627 0a52 6571  tra == 'dev'.Req
-00000630: 7569 7265 732d 4469 7374 3a20 7079 7465  uires-Dist: pyte
-00000640: 7374 203b 2065 7874 7261 203d 3d20 2764  st ; extra == 'd
-00000650: 6576 270a 5265 7175 6972 6573 2d44 6973  ev'.Requires-Dis
-00000660: 743a 2070 7974 6573 742d 7370 6869 6e78  t: pytest-sphinx
-00000670: 203b 2065 7874 7261 203d 3d20 2764 6576   ; extra == 'dev
-00000680: 270a 5265 7175 6972 6573 2d44 6973 743a  '.Requires-Dist:
-00000690: 2070 7974 6573 742d 6173 796e 6369 6f20   pytest-asyncio 
-000006a0: 3b20 6578 7472 6120 3d3d 2027 6465 7627  ; extra == 'dev'
-000006b0: 0a52 6571 7569 7265 732d 4469 7374 3a20  .Requires-Dist: 
-000006c0: 7663 7270 7920 3b20 6578 7472 6120 3d3d  vcrpy ; extra ==
-000006d0: 2027 6465 7627 0a52 6571 7569 7265 732d   'dev'.Requires-
-000006e0: 4469 7374 3a20 7079 7465 7374 2d63 6f76  Dist: pytest-cov
-000006f0: 203b 2065 7874 7261 203d 3d20 2764 6576   ; extra == 'dev
-00000700: 270a 5265 7175 6972 6573 2d44 6973 743a  '.Requires-Dist:
-00000710: 2074 7769 6e65 2028 3e3d 312e 3131 2e30   twine (>=1.11.0
-00000720: 2920 3b20 6578 7472 6120 3d3d 2027 6465  ) ; extra == 'de
-00000730: 7627 0a52 6571 7569 7265 732d 4469 7374  v'.Requires-Dist
-00000740: 3a20 7365 7475 7074 6f6f 6c73 203b 2065  : setuptools ; e
-00000750: 7874 7261 203d 3d20 2764 6576 270a 5265  xtra == 'dev'.Re
-00000760: 7175 6972 6573 2d44 6973 743a 2077 6865  quires-Dist: whe
-00000770: 656c 203b 2065 7874 7261 203d 3d20 2764  el ; extra == 'd
-00000780: 6576 270a 5265 7175 6972 6573 2d44 6973  ev'.Requires-Dis
-00000790: 743a 2053 7068 696e 7820 283c 352e 312e  t: Sphinx (<5.1.
-000007a0: 302c 3e3d 342e 332e 3029 203b 2065 7874  0,>=4.3.0) ; ext
+00000490: 7465 6e61 6369 7479 0a52 6571 7569 7265  tenacity.Require
+000004a0: 732d 4469 7374 3a20 7465 726d 636f 6c6f  s-Dist: termcolo
+000004b0: 720a 5265 7175 6972 6573 2d44 6973 743a  r.Requires-Dist:
+000004c0: 2074 7164 6d0a 5265 7175 6972 6573 2d44   tqdm.Requires-D
+000004d0: 6973 743a 2075 726c 6c69 6233 2028 3c32  ist: urllib3 (<2
+000004e0: 2e30 2e30 290a 5072 6f76 6964 6573 2d45  .0.0).Provides-E
+000004f0: 7874 7261 3a20 6465 706c 6f79 0a52 6571  xtra: deploy.Req
+00000500: 7569 7265 732d 4469 7374 3a20 636c 6f75  uires-Dist: clou
+00000510: 6470 6963 6b6c 6520 3b20 6578 7472 6120  dpickle ; extra 
+00000520: 3d3d 2027 6465 706c 6f79 270a 5265 7175  == 'deploy'.Requ
+00000530: 6972 6573 2d44 6973 743a 2074 7261 6e73  ires-Dist: trans
+00000540: 666f 726d 6572 7320 3b20 6578 7472 6120  formers ; extra 
+00000550: 3d3d 2027 6465 706c 6f79 270a 5265 7175  == 'deploy'.Requ
+00000560: 6972 6573 2d44 6973 743a 2073 6369 6b69  ires-Dist: sciki
+00000570: 742d 6c65 6172 6e20 3b20 6578 7472 6120  t-learn ; extra 
+00000580: 3d3d 2027 6465 706c 6f79 270a 5072 6f76  == 'deploy'.Prov
+00000590: 6964 6573 2d45 7874 7261 3a20 6465 760a  ides-Extra: dev.
+000005a0: 5265 7175 6972 6573 2d44 6973 743a 2066  Requires-Dist: f
+000005b0: 6c61 6b65 3820 283d 3d35 2e30 2e34 2920  lake8 (==5.0.4) 
+000005c0: 3b20 6578 7472 6120 3d3d 2027 6465 7627  ; extra == 'dev'
+000005d0: 0a52 6571 7569 7265 732d 4469 7374 3a20  .Requires-Dist: 
+000005e0: 7079 6c69 6e74 2028 3d3d 322e 3135 2e30  pylint (==2.15.0
+000005f0: 2920 3b20 6578 7472 6120 3d3d 2027 6465  ) ; extra == 'de
+00000600: 7627 0a52 6571 7569 7265 732d 4469 7374  v'.Requires-Dist
+00000610: 3a20 626c 6163 6b20 283d 3d32 322e 382e  : black (==22.8.
+00000620: 3029 203b 2065 7874 7261 203d 3d20 2764  0) ; extra == 'd
+00000630: 6576 270a 5265 7175 6972 6573 2d44 6973  ev'.Requires-Dis
+00000640: 743a 2069 736f 7274 2028 3d3d 352e 3130  t: isort (==5.10
+00000650: 2e31 2920 3b20 6578 7472 6120 3d3d 2027  .1) ; extra == '
+00000660: 6465 7627 0a52 6571 7569 7265 732d 4469  dev'.Requires-Di
+00000670: 7374 3a20 7079 7465 7374 203b 2065 7874  st: pytest ; ext
+00000680: 7261 203d 3d20 2764 6576 270a 5265 7175  ra == 'dev'.Requ
+00000690: 6972 6573 2d44 6973 743a 2070 7974 6573  ires-Dist: pytes
+000006a0: 742d 7370 6869 6e78 203b 2065 7874 7261  t-sphinx ; extra
+000006b0: 203d 3d20 2764 6576 270a 5265 7175 6972   == 'dev'.Requir
+000006c0: 6573 2d44 6973 743a 2070 7974 6573 742d  es-Dist: pytest-
+000006d0: 6173 796e 6369 6f20 3b20 6578 7472 6120  asyncio ; extra 
+000006e0: 3d3d 2027 6465 7627 0a52 6571 7569 7265  == 'dev'.Require
+000006f0: 732d 4469 7374 3a20 7663 7270 7920 3b20  s-Dist: vcrpy ; 
+00000700: 6578 7472 6120 3d3d 2027 6465 7627 0a52  extra == 'dev'.R
+00000710: 6571 7569 7265 732d 4469 7374 3a20 7079  equires-Dist: py
+00000720: 7465 7374 2d63 6f76 203b 2065 7874 7261  test-cov ; extra
+00000730: 203d 3d20 2764 6576 270a 5265 7175 6972   == 'dev'.Requir
+00000740: 6573 2d44 6973 743a 2074 7769 6e65 2028  es-Dist: twine (
+00000750: 3e3d 312e 3131 2e30 2920 3b20 6578 7472  >=1.11.0) ; extr
+00000760: 6120 3d3d 2027 6465 7627 0a52 6571 7569  a == 'dev'.Requi
+00000770: 7265 732d 4469 7374 3a20 7365 7475 7074  res-Dist: setupt
+00000780: 6f6f 6c73 203b 2065 7874 7261 203d 3d20  ools ; extra == 
+00000790: 2764 6576 270a 5265 7175 6972 6573 2d44  'dev'.Requires-D
+000007a0: 6973 743a 2077 6865 656c 203b 2065 7874  ist: wheel ; ext
 000007b0: 7261 203d 3d20 2764 6576 270a 5265 7175  ra == 'dev'.Requ
-000007c0: 6972 6573 2d44 6973 743a 2066 7572 6f20  ires-Dist: furo 
-000007d0: 283d 3d32 3032 322e 362e 342e 3129 203b  (==2022.6.4.1) ;
-000007e0: 2065 7874 7261 203d 3d20 2764 6576 270a   extra == 'dev'.
-000007f0: 5265 7175 6972 6573 2d44 6973 743a 206d  Requires-Dist: m
-00000800: 7973 742d 7061 7273 6572 2028 3c31 2e31  yst-parser (<1.1
-00000810: 2e30 2c3e 3d30 2e31 352e 3229 203b 2065  .0,>=0.15.2) ; e
-00000820: 7874 7261 203d 3d20 2764 6576 270a 5265  xtra == 'dev'.Re
-00000830: 7175 6972 6573 2d44 6973 743a 2073 7068  quires-Dist: sph
-00000840: 696e 782d 636f 7079 6275 7474 6f6e 2028  inx-copybutton (
-00000850: 3d3d 302e 352e 3029 203b 2065 7874 7261  ==0.5.0) ; extra
-00000860: 203d 3d20 2764 6576 270a 5265 7175 6972   == 'dev'.Requir
-00000870: 6573 2d44 6973 743a 2073 7068 696e 782d  es-Dist: sphinx-
-00000880: 6175 746f 6275 696c 6420 283d 3d32 3032  autobuild (==202
-00000890: 312e 332e 3134 2920 3b20 6578 7472 6120  1.3.14) ; extra 
-000008a0: 3d3d 2027 6465 7627 0a52 6571 7569 7265  == 'dev'.Require
-000008b0: 732d 4469 7374 3a20 7370 6869 6e78 2d61  s-Dist: sphinx-a
-000008c0: 7574 6f64 6f63 2d74 7970 6568 696e 7473  utodoc-typehints
-000008d0: 203b 2065 7874 7261 203d 3d20 2764 6576   ; extra == 'dev
-000008e0: 270a 5265 7175 6972 6573 2d44 6973 743a  '.Requires-Dist:
-000008f0: 2073 7068 696e 782d 6465 7369 676e 203b   sphinx-design ;
-00000900: 2065 7874 7261 203d 3d20 2764 6576 270a   extra == 'dev'.
-00000910: 5265 7175 6972 6573 2d44 6973 743a 2070  Requires-Dist: p
-00000920: 6163 6b61 6769 6e67 203b 2065 7874 7261  ackaging ; extra
-00000930: 203d 3d20 2764 6576 270a 5265 7175 6972   == 'dev'.Requir
-00000940: 6573 2d44 6973 743a 2061 696f 6874 7470  es-Dist: aiohttp
-00000950: 203b 2065 7874 7261 203d 3d20 2764 6576   ; extra == 'dev
-00000960: 270a 5265 7175 6972 6573 2d44 6973 743a  '.Requires-Dist:
-00000970: 2064 6174 6172 6f62 6f74 203b 2065 7874   datarobot ; ext
-00000980: 7261 203d 3d20 2764 6576 270a 5265 7175  ra == 'dev'.Requ
-00000990: 6972 6573 2d44 6973 743a 2069 7079 7468  ires-Dist: ipyth
-000009a0: 6f6e 203b 2065 7874 7261 203d 3d20 2764  on ; extra == 'd
-000009b0: 6576 270a 5265 7175 6972 6573 2d44 6973  ev'.Requires-Dis
-000009c0: 743a 2069 7079 7769 6467 6574 7320 283d  t: ipywidgets (=
-000009d0: 3d37 2e37 2e32 2920 3b20 6578 7472 6120  =7.7.2) ; extra 
-000009e0: 3d3d 2027 6465 7627 0a52 6571 7569 7265  == 'dev'.Require
-000009f0: 732d 4469 7374 3a20 6e61 6d65 732d 6765  s-Dist: names-ge
-00000a00: 6e65 7261 746f 7220 3b20 6578 7472 6120  nerator ; extra 
-00000a10: 3d3d 2027 6465 7627 0a52 6571 7569 7265  == 'dev'.Require
-00000a20: 732d 4469 7374 3a20 7061 6e64 6173 203b  s-Dist: pandas ;
-00000a30: 2065 7874 7261 203d 3d20 2764 6576 270a   extra == 'dev'.
-00000a40: 5265 7175 6972 6573 2d44 6973 743a 2050  Requires-Dist: P
-00000a50: 7959 616d 6c20 3b20 6578 7472 6120 3d3d  yYaml ; extra ==
-00000a60: 2027 6465 7627 0a52 6571 7569 7265 732d   'dev'.Requires-
-00000a70: 4469 7374 3a20 7465 726d 636f 6c6f 7220  Dist: termcolor 
-00000a80: 3b20 6578 7472 6120 3d3d 2027 6465 7627  ; extra == 'dev'
-00000a90: 0a52 6571 7569 7265 732d 4469 7374 3a20  .Requires-Dist: 
-00000aa0: 7471 646d 203b 2065 7874 7261 203d 3d20  tqdm ; extra == 
-00000ab0: 2764 6576 270a 5265 7175 6972 6573 2d44  'dev'.Requires-D
-00000ac0: 6973 743a 2061 6c74 6169 7220 3b20 6578  ist: altair ; ex
-00000ad0: 7472 6120 3d3d 2027 6465 7627 0a52 6571  tra == 'dev'.Req
-00000ae0: 7569 7265 732d 4469 7374 3a20 636c 6f75  uires-Dist: clou
-00000af0: 6470 6963 6b6c 6520 3b20 6578 7472 6120  dpickle ; extra 
-00000b00: 3d3d 2027 6465 7627 0a52 6571 7569 7265  == 'dev'.Require
-00000b10: 732d 4469 7374 3a20 7472 616e 7366 6f72  s-Dist: transfor
-00000b20: 6d65 7273 203b 2065 7874 7261 203d 3d20  mers ; extra == 
-00000b30: 2764 6576 270a 5265 7175 6972 6573 2d44  'dev'.Requires-D
-00000b40: 6973 743a 2073 6369 6b69 742d 6c65 6172  ist: scikit-lear
-00000b50: 6e20 3b20 6578 7472 6120 3d3d 2027 6465  n ; extra == 'de
-00000b60: 7627 0a52 6571 7569 7265 732d 4469 7374  v'.Requires-Dist
-00000b70: 3a20 7079 7370 6172 6b20 3b20 6578 7472  : pyspark ; extr
-00000b80: 6120 3d3d 2027 6465 7627 0a52 6571 7569  a == 'dev'.Requi
-00000b90: 7265 732d 4469 7374 3a20 6d79 7079 2028  res-Dist: mypy (
-00000ba0: 3d3d 312e 302e 3029 203b 2065 7874 7261  ==1.0.0) ; extra
-00000bb0: 203d 3d20 2764 6576 270a 5072 6f76 6964   == 'dev'.Provid
-00000bc0: 6573 2d45 7874 7261 3a20 7370 6172 6b0a  es-Extra: spark.
-00000bd0: 5265 7175 6972 6573 2d44 6973 743a 2070  Requires-Dist: p
-00000be0: 7973 7061 726b 203b 2065 7874 7261 203d  yspark ; extra =
-00000bf0: 3d20 2773 7061 726b 270a 0a3c 696d 6720  = 'spark'..<img 
-00000c00: 616c 6967 6e3d 2263 656e 7465 7222 2073  align="center" s
-00000c10: 7263 3d22 6874 7470 733a 2f2f 7333 2e61  rc="https://s3.a
-00000c20: 6d61 7a6f 6e61 7773 2e63 6f6d 2f64 6174  mazonaws.com/dat
-00000c30: 6172 6f62 6f74 5f70 7562 6c69 632f 6472  arobot_public/dr
-00000c40: 782f 6472 785f 6769 6673 2f6c 6f67 6f2e  x/drx_gifs/logo.
-00000c50: 706e 6722 2061 6c74 3d22 6472 7822 3e0a  png" alt="drx">.
-00000c60: 0a21 5b50 7950 495d 2868 7474 7073 3a2f  .![PyPI](https:/
-00000c70: 2f69 6d67 2e73 6869 656c 6473 2e69 6f2f  /img.shields.io/
-00000c80: 7079 7069 2f76 2f64 6174 6172 6f62 6f74  pypi/v/datarobot
-00000c90: 7829 0a21 5b50 7950 4920 2d20 5079 7468  x).![PyPI - Pyth
-00000ca0: 6f6e 2056 6572 7369 6f6e 5d28 6874 7470  on Version](http
-00000cb0: 733a 2f2f 696d 672e 7368 6965 6c64 732e  s://img.shields.
-00000cc0: 696f 2f70 7970 692f 7079 7665 7273 696f  io/pypi/pyversio
-00000cd0: 6e73 2f64 6174 6172 6f62 6f74 7829 0a21  ns/datarobotx).!
-00000ce0: 5b50 7950 4920 2d20 466f 726d 6174 5d28  [PyPI - Format](
-00000cf0: 6874 7470 733a 2f2f 696d 672e 7368 6965  https://img.shie
-00000d00: 6c64 732e 696f 2f70 7970 692f 666f 726d  lds.io/pypi/form
-00000d10: 6174 2f64 6174 6172 6f62 6f74 7829 0a0a  at/datarobotx)..
-00000d20: 2a44 6174 6152 6f62 6f74 582a 2069 7320  *DataRobotX* is 
-00000d30: 6120 636f 6c6c 6563 7469 6f6e 206f 6620  a collection of 
-00000d40: 4461 7461 526f 626f 7420 6578 7465 6e73  DataRobot extens
-00000d50: 696f 6e73 2064 6573 6967 6e65 6420 746f  ions designed to
-00000d60: 2065 6e68 616e 6365 2074 6865 2064 6174   enhance the dat
-00000d70: 6120 7363 6965 6e63 6520 6578 7065 7269  a science experi
-00000d80: 656e 6365 2e0a 0a43 6865 636b 206f 7574  ence...Check out
-00000d90: 206f 7572 205b 646f 6375 6d65 6e74 6174   our [documentat
-00000da0: 696f 6e5d 2868 7474 7073 3a2f 2f64 6174  ion](https://dat
-00000db0: 6172 6f62 6f74 2e67 6974 6875 622e 696f  arobot.github.io
-00000dc0: 2f64 7278 2920 746f 2067 6574 2073 7461  /drx) to get sta
-00000dd0: 7274 6564 2e0a 0a54 6869 7320 7061 636b  rted...This pack
-00000de0: 6167 6520 6973 2072 656c 6561 7365 6420  age is released 
-00000df0: 756e 6465 7220 7468 6520 7465 726d 7320  under the terms 
-00000e00: 6f66 2074 6865 2044 6174 6152 6f62 6f74  of the DataRobot
-00000e10: 2054 6f6f 6c20 616e 6420 5574 696c 6974   Tool and Utilit
-00000e20: 7920 4167 7265 656d 656e 742c 2077 6869  y Agreement, whi
-00000e30: 6368 2063 616e 2062 6520 666f 756e 6420  ch can be found 
-00000e40: 6f6e 206f 7572 205b 4c65 6761 6c5d 2868  on our [Legal](h
-00000e50: 7474 7073 3a2f 2f77 7777 2e64 6174 6172  ttps://www.datar
-00000e60: 6f62 6f74 2e63 6f6d 2f6c 6567 616c 2f29  obot.com/legal/)
-00000e70: 2070 6167 652c 2061 6c6f 6e67 2077 6974   page, along wit
-00000e80: 6820 6f75 7220 7072 6976 6163 7920 706f  h our privacy po
-00000e90: 6c69 6379 2061 6e64 206d 6f72 652e 0a0a  licy and more...
-00000ea0: 3c74 6162 6c65 3e0a 3c74 626f 6479 3e3c  <table>.<tbody><
-00000eb0: 7472 3e0a 3c74 643e 3c73 7472 6f6e 673e  tr>.<td><strong>
-00000ec0: 5369 6d70 6c65 2073 796e 7461 783c 2f73  Simple syntax</s
-00000ed0: 7472 6f6e 673e 3c2f 7464 3e0a 3c74 643e  trong></td>.<td>
-00000ee0: 3c69 6d67 2073 7263 3d22 6874 7470 733a  <img src="https:
-00000ef0: 2f2f 7333 2e61 6d61 7a6f 6e61 7773 2e63  //s3.amazonaws.c
-00000f00: 6f6d 2f64 6174 6172 6f62 6f74 5f70 7562  om/datarobot_pub
-00000f10: 6c69 632f 6472 782f 6472 785f 6769 6673  lic/drx/drx_gifs
-00000f20: 2f69 6e74 726f 5f67 6966 2e67 6966 2220  /intro_gif.gif" 
-00000f30: 616c 743d 2249 6e74 726f 223e 3c2f 7464  alt="Intro"></td
-00000f40: 3e0a 3c2f 7472 3e0a 3c74 723e 0a3c 7464  >.</tr>.<tr>.<td
-00000f50: 3e3c 7374 726f 6e67 3e45 6173 7920 7072  ><strong>Easy pr
-00000f60: 6564 6963 7469 6f6e 733c 2f73 7472 6f6e  edictions</stron
-00000f70: 673e 3c2f 7464 3e0a 3c74 643e 3c69 6d67  g></td>.<td><img
-00000f80: 2073 7263 3d22 6874 7470 733a 2f2f 7333   src="https://s3
-00000f90: 2e61 6d61 7a6f 6e61 7773 2e63 6f6d 2f64  .amazonaws.com/d
-00000fa0: 6174 6172 6f62 6f74 5f70 7562 6c69 632f  atarobot_public/
-00000fb0: 6472 782f 6472 785f 6769 6673 2f70 7265  drx/drx_gifs/pre
-00000fc0: 6469 6374 696f 6e73 5f67 6966 2e67 6966  dictions_gif.gif
-00000fd0: 2220 616c 743d 2250 7265 6469 6374 223e  " alt="Predict">
-00000fe0: 3c2f 7464 3e0a 3c2f 7472 3e0a 3c74 723e  </td>.</tr>.<tr>
-00000ff0: 0a3c 7464 3e3c 7374 726f 6e67 3e53 6561  .<td><strong>Sea
-00001000: 6d6c 6573 7320 6173 796e 633c 2f73 7472  mless async</str
-00001010: 6f6e 673e 3c2f 7464 3e0a 3c74 643e 3c69  ong></td>.<td><i
-00001020: 6d67 2073 7263 3d22 6874 7470 733a 2f2f  mg src="https://
-00001030: 7333 2e61 6d61 7a6f 6e61 7773 2e63 6f6d  s3.amazonaws.com
-00001040: 2f64 6174 6172 6f62 6f74 5f70 7562 6c69  /datarobot_publi
-00001050: 632f 6472 782f 6472 785f 6769 6673 2f61  c/drx/drx_gifs/a
-00001060: 7379 6e63 5f67 6966 2e67 6966 2220 616c  sync_gif.gif" al
-00001070: 743d 2241 7379 6e63 223e 3c2f 7464 3e0a  t="Async"></td>.
-00001080: 3c2f 7472 3e0a 3c74 723e 0a3c 7464 3e3c  </tr>.<tr>.<td><
-00001090: 7374 726f 6e67 3e44 796e 616d 6963 2077  strong>Dynamic w
-000010a0: 6964 6765 7473 3c2f 7374 726f 6e67 3e3c  idgets</strong><
-000010b0: 2f74 643e 0a3c 7464 3e3c 696d 6720 7372  /td>.<td><img sr
-000010c0: 633d 2268 7474 7073 3a2f 2f73 332e 616d  c="https://s3.am
-000010d0: 617a 6f6e 6177 732e 636f 6d2f 6461 7461  azonaws.com/data
-000010e0: 726f 626f 745f 7075 626c 6963 2f64 7278  robot_public/drx
-000010f0: 2f64 7278 5f67 6966 732f 4576 616c 7561  /drx_gifs/Evalua
-00001100: 7465 5769 6467 6574 2e67 6966 2220 616c  teWidget.gif" al
-00001110: 743d 2257 6964 6765 7422 3e3c 2f74 643e  t="Widget"></td>
-00001120: 0a3c 2f74 723e 0a3c 7472 3e0a 3c74 643e  .</tr>.<tr>.<td>
-00001130: 3c73 7472 6f6e 673e 436f 6e66 6967 2068  <strong>Config h
-00001140: 656c 7065 7273 3c2f 7374 726f 6e67 3e3c  elpers</strong><
-00001150: 2f74 643e 0a3c 7464 3e3c 696d 6720 7372  /td>.<td><img sr
-00001160: 633d 2268 7474 7073 3a2f 2f73 332e 616d  c="https://s3.am
-00001170: 617a 6f6e 6177 732e 636f 6d2f 6461 7461  azonaws.com/data
-00001180: 726f 626f 745f 7075 626c 6963 2f64 7278  robot_public/drx
-00001190: 2f64 7278 5f67 6966 732f 636f 6465 5f63  /drx_gifs/code_c
-000011a0: 6f6d 706c 6574 655f 6769 662e 6769 6622  omplete_gif.gif"
-000011b0: 2061 6c74 3d22 4e61 7669 6761 7465 223e   alt="Navigate">
-000011c0: 3c2f 7464 3e0a 3c2f 7472 3e0a 3c74 723e  </td>.</tr>.<tr>
-000011d0: 0a3c 7464 3e3c 7374 726f 6e67 3e45 7874  .<td><strong>Ext
-000011e0: 656e 7369 6f6e 733c 2f73 7472 6f6e 673e  ensions</strong>
-000011f0: 3c2f 7464 3e0a 3c74 643e 3c69 6d67 2073  </td>.<td><img s
-00001200: 7263 3d22 6874 7470 733a 2f2f 7333 2e61  rc="https://s3.a
-00001210: 6d61 7a6f 6e61 7773 2e63 6f6d 2f64 6174  mazonaws.com/dat
-00001220: 6172 6f62 6f74 5f70 7562 6c69 632f 6472  arobot_public/dr
-00001230: 782f 6472 785f 6769 6673 2f73 656c 665f  x/drx_gifs/self_
-00001240: 6469 7363 6f76 6572 795f 6769 662e 6769  discovery_gif.gi
-00001250: 6622 2061 6c74 3d22 4578 7465 6e64 223e  f" alt="Extend">
-00001260: 3c2f 7464 3e0a 3c2f 7472 3e0a 3c2f 7462  </td>.</tr>.</tb
-00001270: 6f64 793e 3c2f 7461 626c 653e 0a         ody></table>.
+000007c0: 6972 6573 2d44 6973 743a 2053 7068 696e  ires-Dist: Sphin
+000007d0: 7820 283c 352e 312e 302c 3e3d 342e 332e  x (<5.1.0,>=4.3.
+000007e0: 3029 203b 2065 7874 7261 203d 3d20 2764  0) ; extra == 'd
+000007f0: 6576 270a 5265 7175 6972 6573 2d44 6973  ev'.Requires-Dis
+00000800: 743a 2066 7572 6f20 283d 3d32 3032 322e  t: furo (==2022.
+00000810: 362e 342e 3129 203b 2065 7874 7261 203d  6.4.1) ; extra =
+00000820: 3d20 2764 6576 270a 5265 7175 6972 6573  = 'dev'.Requires
+00000830: 2d44 6973 743a 206d 7973 742d 7061 7273  -Dist: myst-pars
+00000840: 6572 2028 3c31 2e31 2e30 2c3e 3d30 2e31  er (<1.1.0,>=0.1
+00000850: 352e 3229 203b 2065 7874 7261 203d 3d20  5.2) ; extra == 
+00000860: 2764 6576 270a 5265 7175 6972 6573 2d44  'dev'.Requires-D
+00000870: 6973 743a 2073 7068 696e 782d 636f 7079  ist: sphinx-copy
+00000880: 6275 7474 6f6e 2028 3d3d 302e 352e 3029  button (==0.5.0)
+00000890: 203b 2065 7874 7261 203d 3d20 2764 6576   ; extra == 'dev
+000008a0: 270a 5265 7175 6972 6573 2d44 6973 743a  '.Requires-Dist:
+000008b0: 2073 7068 696e 782d 6175 746f 6275 696c   sphinx-autobuil
+000008c0: 6420 283d 3d32 3032 312e 332e 3134 2920  d (==2021.3.14) 
+000008d0: 3b20 6578 7472 6120 3d3d 2027 6465 7627  ; extra == 'dev'
+000008e0: 0a52 6571 7569 7265 732d 4469 7374 3a20  .Requires-Dist: 
+000008f0: 7370 6869 6e78 2d61 7574 6f64 6f63 2d74  sphinx-autodoc-t
+00000900: 7970 6568 696e 7473 203b 2065 7874 7261  ypehints ; extra
+00000910: 203d 3d20 2764 6576 270a 5265 7175 6972   == 'dev'.Requir
+00000920: 6573 2d44 6973 743a 2073 7068 696e 782d  es-Dist: sphinx-
+00000930: 6465 7369 676e 203b 2065 7874 7261 203d  design ; extra =
+00000940: 3d20 2764 6576 270a 5265 7175 6972 6573  = 'dev'.Requires
+00000950: 2d44 6973 743a 2070 6163 6b61 6769 6e67  -Dist: packaging
+00000960: 203b 2065 7874 7261 203d 3d20 2764 6576   ; extra == 'dev
+00000970: 270a 5265 7175 6972 6573 2d44 6973 743a  '.Requires-Dist:
+00000980: 2061 696f 6874 7470 203b 2065 7874 7261   aiohttp ; extra
+00000990: 203d 3d20 2764 6576 270a 5265 7175 6972   == 'dev'.Requir
+000009a0: 6573 2d44 6973 743a 2064 6174 6172 6f62  es-Dist: datarob
+000009b0: 6f74 203b 2065 7874 7261 203d 3d20 2764  ot ; extra == 'd
+000009c0: 6576 270a 5265 7175 6972 6573 2d44 6973  ev'.Requires-Dis
+000009d0: 743a 2069 7079 7468 6f6e 2028 3c38 2e31  t: ipython (<8.1
+000009e0: 332e 3029 203b 2065 7874 7261 203d 3d20  3.0) ; extra == 
+000009f0: 2764 6576 270a 5265 7175 6972 6573 2d44  'dev'.Requires-D
+00000a00: 6973 743a 2069 7079 7769 6467 6574 7320  ist: ipywidgets 
+00000a10: 283d 3d37 2e37 2e32 2920 3b20 6578 7472  (==7.7.2) ; extr
+00000a20: 6120 3d3d 2027 6465 7627 0a52 6571 7569  a == 'dev'.Requi
+00000a30: 7265 732d 4469 7374 3a20 6e61 6d65 732d  res-Dist: names-
+00000a40: 6765 6e65 7261 746f 7220 3b20 6578 7472  generator ; extr
+00000a50: 6120 3d3d 2027 6465 7627 0a52 6571 7569  a == 'dev'.Requi
+00000a60: 7265 732d 4469 7374 3a20 7061 6e64 6173  res-Dist: pandas
+00000a70: 203b 2065 7874 7261 203d 3d20 2764 6576   ; extra == 'dev
+00000a80: 270a 5265 7175 6972 6573 2d44 6973 743a  '.Requires-Dist:
+00000a90: 2050 7959 616d 6c20 3b20 6578 7472 6120   PyYaml ; extra 
+00000aa0: 3d3d 2027 6465 7627 0a52 6571 7569 7265  == 'dev'.Require
+00000ab0: 732d 4469 7374 3a20 7465 6e61 6369 7479  s-Dist: tenacity
+00000ac0: 203b 2065 7874 7261 203d 3d20 2764 6576   ; extra == 'dev
+00000ad0: 270a 5265 7175 6972 6573 2d44 6973 743a  '.Requires-Dist:
+00000ae0: 2074 6572 6d63 6f6c 6f72 203b 2065 7874   termcolor ; ext
+00000af0: 7261 203d 3d20 2764 6576 270a 5265 7175  ra == 'dev'.Requ
+00000b00: 6972 6573 2d44 6973 743a 2074 7164 6d20  ires-Dist: tqdm 
+00000b10: 3b20 6578 7472 6120 3d3d 2027 6465 7627  ; extra == 'dev'
+00000b20: 0a52 6571 7569 7265 732d 4469 7374 3a20  .Requires-Dist: 
+00000b30: 616c 7461 6972 203b 2065 7874 7261 203d  altair ; extra =
+00000b40: 3d20 2764 6576 270a 5265 7175 6972 6573  = 'dev'.Requires
+00000b50: 2d44 6973 743a 2063 6c6f 7564 7069 636b  -Dist: cloudpick
+00000b60: 6c65 203b 2065 7874 7261 203d 3d20 2764  le ; extra == 'd
+00000b70: 6576 270a 5265 7175 6972 6573 2d44 6973  ev'.Requires-Dis
+00000b80: 743a 2074 7261 6e73 666f 726d 6572 7320  t: transformers 
+00000b90: 3b20 6578 7472 6120 3d3d 2027 6465 7627  ; extra == 'dev'
+00000ba0: 0a52 6571 7569 7265 732d 4469 7374 3a20  .Requires-Dist: 
+00000bb0: 7363 696b 6974 2d6c 6561 726e 203b 2065  scikit-learn ; e
+00000bc0: 7874 7261 203d 3d20 2764 6576 270a 5265  xtra == 'dev'.Re
+00000bd0: 7175 6972 6573 2d44 6973 743a 2070 7973  quires-Dist: pys
+00000be0: 7061 726b 203b 2065 7874 7261 203d 3d20  park ; extra == 
+00000bf0: 2764 6576 270a 5265 7175 6972 6573 2d44  'dev'.Requires-D
+00000c00: 6973 743a 206f 7065 6e61 6920 3b20 6578  ist: openai ; ex
+00000c10: 7472 6120 3d3d 2027 6465 7627 0a52 6571  tra == 'dev'.Req
+00000c20: 7569 7265 732d 4469 7374 3a20 6d79 7079  uires-Dist: mypy
+00000c30: 2028 3d3d 312e 302e 3029 203b 2065 7874   (==1.0.0) ; ext
+00000c40: 7261 203d 3d20 2764 6576 270a 5265 7175  ra == 'dev'.Requ
+00000c50: 6972 6573 2d44 6973 743a 2075 726c 6c69  ires-Dist: urlli
+00000c60: 6233 2028 3c32 2e30 2e30 2920 3b20 6578  b3 (<2.0.0) ; ex
+00000c70: 7472 6120 3d3d 2027 6465 7627 0a52 6571  tra == 'dev'.Req
+00000c80: 7569 7265 732d 4469 7374 3a20 6c61 6e67  uires-Dist: lang
+00000c90: 6368 6169 6e20 3b20 2870 7974 686f 6e5f  chain ; (python_
+00000ca0: 7665 7273 696f 6e20 3e3d 2022 332e 3822  version >= "3.8"
+00000cb0: 2920 616e 6420 6578 7472 6120 3d3d 2027  ) and extra == '
+00000cc0: 6465 7627 0a52 6571 7569 7265 732d 4469  dev'.Requires-Di
+00000cd0: 7374 3a20 7079 6461 6e74 6963 203b 2028  st: pydantic ; (
+00000ce0: 7079 7468 6f6e 5f76 6572 7369 6f6e 203e  python_version >
+00000cf0: 3d20 2233 2e38 2229 2061 6e64 2065 7874  = "3.8") and ext
+00000d00: 7261 203d 3d20 2764 6576 270a 5265 7175  ra == 'dev'.Requ
+00000d10: 6972 6573 2d44 6973 743a 2074 696b 746f  ires-Dist: tikto
+00000d20: 6b65 6e20 283d 3d30 2e33 2e33 2920 3b20  ken (==0.3.3) ; 
+00000d30: 2870 7974 686f 6e5f 7665 7273 696f 6e20  (python_version 
+00000d40: 3e3d 2022 332e 3822 2920 616e 6420 6578  >= "3.8") and ex
+00000d50: 7472 6120 3d3d 2027 6465 7627 0a50 726f  tra == 'dev'.Pro
+00000d60: 7669 6465 732d 4578 7472 613a 206c 6c6d  vides-Extra: llm
+00000d70: 0a52 6571 7569 7265 732d 4469 7374 3a20  .Requires-Dist: 
+00000d80: 6c61 6e67 6368 6169 6e20 3b20 6578 7472  langchain ; extr
+00000d90: 6120 3d3d 2027 6c6c 6d27 0a52 6571 7569  a == 'llm'.Requi
+00000da0: 7265 732d 4469 7374 3a20 7079 6461 6e74  res-Dist: pydant
+00000db0: 6963 203b 2065 7874 7261 203d 3d20 276c  ic ; extra == 'l
+00000dc0: 6c6d 270a 5265 7175 6972 6573 2d44 6973  lm'.Requires-Dis
+00000dd0: 743a 2074 696b 746f 6b65 6e20 3b20 6578  t: tiktoken ; ex
+00000de0: 7472 6120 3d3d 2027 6c6c 6d27 0a52 6571  tra == 'llm'.Req
+00000df0: 7569 7265 732d 4469 7374 3a20 6f70 656e  uires-Dist: open
+00000e00: 6169 203b 2065 7874 7261 203d 3d20 276c  ai ; extra == 'l
+00000e10: 6c6d 270a 5072 6f76 6964 6573 2d45 7874  lm'.Provides-Ext
+00000e20: 7261 3a20 7370 6172 6b0a 5265 7175 6972  ra: spark.Requir
+00000e30: 6573 2d44 6973 743a 2070 7973 7061 726b  es-Dist: pyspark
+00000e40: 203b 2065 7874 7261 203d 3d20 2773 7061   ; extra == 'spa
+00000e50: 726b 270a 0a3c 696d 6720 616c 6967 6e3d  rk'..<img align=
+00000e60: 2263 656e 7465 7222 2073 7263 3d22 6874  "center" src="ht
+00000e70: 7470 733a 2f2f 7333 2e61 6d61 7a6f 6e61  tps://s3.amazona
+00000e80: 7773 2e63 6f6d 2f64 6174 6172 6f62 6f74  ws.com/datarobot
+00000e90: 5f70 7562 6c69 632f 6472 782f 6472 785f  _public/drx/drx_
+00000ea0: 6769 6673 2f6c 6f67 6f2e 706e 6722 2061  gifs/logo.png" a
+00000eb0: 6c74 3d22 6472 7822 3e0a 0a21 5b50 7950  lt="drx">..![PyP
+00000ec0: 495d 2868 7474 7073 3a2f 2f69 6d67 2e73  I](https://img.s
+00000ed0: 6869 656c 6473 2e69 6f2f 7079 7069 2f76  hields.io/pypi/v
+00000ee0: 2f64 6174 6172 6f62 6f74 7829 0a21 5b50  /datarobotx).![P
+00000ef0: 7950 4920 2d20 5079 7468 6f6e 2056 6572  yPI - Python Ver
+00000f00: 7369 6f6e 5d28 6874 7470 733a 2f2f 696d  sion](https://im
+00000f10: 672e 7368 6965 6c64 732e 696f 2f70 7970  g.shields.io/pyp
+00000f20: 692f 7079 7665 7273 696f 6e73 2f64 6174  i/pyversions/dat
+00000f30: 6172 6f62 6f74 7829 0a21 5b50 7950 4920  arobotx).![PyPI 
+00000f40: 2d20 466f 726d 6174 5d28 6874 7470 733a  - Format](https:
+00000f50: 2f2f 696d 672e 7368 6965 6c64 732e 696f  //img.shields.io
+00000f60: 2f70 7970 692f 666f 726d 6174 2f64 6174  /pypi/format/dat
+00000f70: 6172 6f62 6f74 7829 0a0a 2a44 6174 6152  arobotx)..*DataR
+00000f80: 6f62 6f74 582a 2069 7320 6120 636f 6c6c  obotX* is a coll
+00000f90: 6563 7469 6f6e 206f 6620 4461 7461 526f  ection of DataRo
+00000fa0: 626f 7420 6578 7465 6e73 696f 6e73 2064  bot extensions d
+00000fb0: 6573 6967 6e65 6420 746f 2065 6e68 616e  esigned to enhan
+00000fc0: 6365 2074 6865 2064 6174 6120 7363 6965  ce the data scie
+00000fd0: 6e63 6520 6578 7065 7269 656e 6365 2e0a  nce experience..
+00000fe0: 0a43 6865 636b 206f 7574 206f 7572 205b  .Check out our [
+00000ff0: 646f 6375 6d65 6e74 6174 696f 6e5d 2868  documentation](h
+00001000: 7474 7073 3a2f 2f64 7278 2e64 6174 6172  ttps://drx.datar
+00001010: 6f62 6f74 2e63 6f6d 2f29 2074 6f20 6765  obot.com/) to ge
+00001020: 7420 7374 6172 7465 642e 0a0a 5468 6973  t started...This
+00001030: 2070 6163 6b61 6765 2069 7320 7265 6c65   package is rele
+00001040: 6173 6564 2075 6e64 6572 2074 6865 2074  ased under the t
+00001050: 6572 6d73 206f 6620 7468 6520 4461 7461  erms of the Data
+00001060: 526f 626f 7420 546f 6f6c 2061 6e64 2055  Robot Tool and U
+00001070: 7469 6c69 7479 2041 6772 6565 6d65 6e74  tility Agreement
+00001080: 2c20 7768 6963 6820 6361 6e20 6265 2066  , which can be f
+00001090: 6f75 6e64 206f 6e20 6f75 7220 5b4c 6567  ound on our [Leg
+000010a0: 616c 5d28 6874 7470 733a 2f2f 7777 772e  al](https://www.
+000010b0: 6461 7461 726f 626f 742e 636f 6d2f 6c65  datarobot.com/le
+000010c0: 6761 6c2f 2920 7061 6765 2c20 616c 6f6e  gal/) page, alon
+000010d0: 6720 7769 7468 206f 7572 2070 7269 7661  g with our priva
+000010e0: 6379 2070 6f6c 6963 7920 616e 6420 6d6f  cy policy and mo
+000010f0: 7265 2e0a 0a3c 7461 626c 653e 0a3c 7462  re...<table>.<tb
+00001100: 6f64 793e 3c74 723e 0a3c 7464 3e3c 7374  ody><tr>.<td><st
+00001110: 726f 6e67 3e53 696d 706c 6520 7379 6e74  rong>Simple synt
+00001120: 6178 3c2f 7374 726f 6e67 3e3c 2f74 643e  ax</strong></td>
+00001130: 0a3c 7464 3e3c 696d 6720 7372 633d 2268  .<td><img src="h
+00001140: 7474 7073 3a2f 2f73 332e 616d 617a 6f6e  ttps://s3.amazon
+00001150: 6177 732e 636f 6d2f 6461 7461 726f 626f  aws.com/datarobo
+00001160: 745f 7075 626c 6963 2f64 7278 2f64 7278  t_public/drx/drx
+00001170: 5f67 6966 732f 696e 7472 6f5f 6769 662e  _gifs/intro_gif.
+00001180: 6769 6622 2061 6c74 3d22 496e 7472 6f22  gif" alt="Intro"
+00001190: 3e3c 2f74 643e 0a3c 2f74 723e 0a3c 7472  ></td>.</tr>.<tr
+000011a0: 3e0a 3c74 643e 3c73 7472 6f6e 673e 4561  >.<td><strong>Ea
+000011b0: 7379 2070 7265 6469 6374 696f 6e73 3c2f  sy predictions</
+000011c0: 7374 726f 6e67 3e3c 2f74 643e 0a3c 7464  strong></td>.<td
+000011d0: 3e3c 696d 6720 7372 633d 2268 7474 7073  ><img src="https
+000011e0: 3a2f 2f73 332e 616d 617a 6f6e 6177 732e  ://s3.amazonaws.
+000011f0: 636f 6d2f 6461 7461 726f 626f 745f 7075  com/datarobot_pu
+00001200: 626c 6963 2f64 7278 2f64 7278 5f67 6966  blic/drx/drx_gif
+00001210: 732f 7072 6564 6963 7469 6f6e 735f 6769  s/predictions_gi
+00001220: 662e 6769 6622 2061 6c74 3d22 5072 6564  f.gif" alt="Pred
+00001230: 6963 7422 3e3c 2f74 643e 0a3c 2f74 723e  ict"></td>.</tr>
+00001240: 0a3c 7472 3e0a 3c74 643e 3c73 7472 6f6e  .<tr>.<td><stron
+00001250: 673e 5365 616d 6c65 7373 2061 7379 6e63  g>Seamless async
+00001260: 3c2f 7374 726f 6e67 3e3c 2f74 643e 0a3c  </strong></td>.<
+00001270: 7464 3e3c 696d 6720 7372 633d 2268 7474  td><img src="htt
+00001280: 7073 3a2f 2f73 332e 616d 617a 6f6e 6177  ps://s3.amazonaw
+00001290: 732e 636f 6d2f 6461 7461 726f 626f 745f  s.com/datarobot_
+000012a0: 7075 626c 6963 2f64 7278 2f64 7278 5f67  public/drx/drx_g
+000012b0: 6966 732f 6173 796e 635f 6769 662e 6769  ifs/async_gif.gi
+000012c0: 6622 2061 6c74 3d22 4173 796e 6322 3e3c  f" alt="Async"><
+000012d0: 2f74 643e 0a3c 2f74 723e 0a3c 7472 3e0a  /td>.</tr>.<tr>.
+000012e0: 3c74 643e 3c73 7472 6f6e 673e 4479 6e61  <td><strong>Dyna
+000012f0: 6d69 6320 7769 6467 6574 733c 2f73 7472  mic widgets</str
+00001300: 6f6e 673e 3c2f 7464 3e0a 3c74 643e 3c69  ong></td>.<td><i
+00001310: 6d67 2073 7263 3d22 6874 7470 733a 2f2f  mg src="https://
+00001320: 7333 2e61 6d61 7a6f 6e61 7773 2e63 6f6d  s3.amazonaws.com
+00001330: 2f64 6174 6172 6f62 6f74 5f70 7562 6c69  /datarobot_publi
+00001340: 632f 6472 782f 6472 785f 6769 6673 2f45  c/drx/drx_gifs/E
+00001350: 7661 6c75 6174 6557 6964 6765 742e 6769  valuateWidget.gi
+00001360: 6622 2061 6c74 3d22 5769 6467 6574 223e  f" alt="Widget">
+00001370: 3c2f 7464 3e0a 3c2f 7472 3e0a 3c74 723e  </td>.</tr>.<tr>
+00001380: 0a3c 7464 3e3c 7374 726f 6e67 3e43 6f6e  .<td><strong>Con
+00001390: 6669 6720 6865 6c70 6572 733c 2f73 7472  fig helpers</str
+000013a0: 6f6e 673e 3c2f 7464 3e0a 3c74 643e 3c69  ong></td>.<td><i
+000013b0: 6d67 2073 7263 3d22 6874 7470 733a 2f2f  mg src="https://
+000013c0: 7333 2e61 6d61 7a6f 6e61 7773 2e63 6f6d  s3.amazonaws.com
+000013d0: 2f64 6174 6172 6f62 6f74 5f70 7562 6c69  /datarobot_publi
+000013e0: 632f 6472 782f 6472 785f 6769 6673 2f63  c/drx/drx_gifs/c
+000013f0: 6f64 655f 636f 6d70 6c65 7465 5f67 6966  ode_complete_gif
+00001400: 2e67 6966 2220 616c 743d 224e 6176 6967  .gif" alt="Navig
+00001410: 6174 6522 3e3c 2f74 643e 0a3c 2f74 723e  ate"></td>.</tr>
+00001420: 0a3c 7472 3e0a 3c74 643e 3c73 7472 6f6e  .<tr>.<td><stron
+00001430: 673e 4578 7465 6e73 696f 6e73 3c2f 7374  g>Extensions</st
+00001440: 726f 6e67 3e3c 2f74 643e 0a3c 7464 3e3c  rong></td>.<td><
+00001450: 696d 6720 7372 633d 2268 7474 7073 3a2f  img src="https:/
+00001460: 2f73 332e 616d 617a 6f6e 6177 732e 636f  /s3.amazonaws.co
+00001470: 6d2f 6461 7461 726f 626f 745f 7075 626c  m/datarobot_publ
+00001480: 6963 2f64 7278 2f64 7278 5f67 6966 732f  ic/drx/drx_gifs/
+00001490: 7365 6c66 5f64 6973 636f 7665 7279 5f67  self_discovery_g
+000014a0: 6966 2e67 6966 2220 616c 743d 2245 7874  if.gif" alt="Ext
+000014b0: 656e 6422 3e3c 2f74 643e 0a3c 2f74 723e  end"></td>.</tr>
+000014c0: 0a3c 2f74 626f 6479 3e3c 2f74 6162 6c65  .</tbody></table
+000014d0: 3e0a                                     >.
```

## Comparing `datarobotx-0.1.4.dist-info/RECORD` & `datarobotx-0.1.5.dist-info/RECORD`

 * *Files 16% similar despite different names*

```diff
@@ -1,49 +1,56 @@
-datarobotx/__init__.py,sha256=METF-f1x8sWtCopTL0KK3WK579XhaAlUMAMCQJ41oew,1499
-datarobotx/_version.py,sha256=Z7gXWDMU9DavPkBUzcxY6K6eXAz0T8hyA-niu2ecuaI,271
+datarobotx/__init__.py,sha256=znA3kfQXkSRBeNke-g_y-KrY4bBPDplDMl2DH_uBUFg,1566
+datarobotx/_version.py,sha256=Wd2aKbia08x43-oHKyIDRGwj7IeEAS1mmza_eA-pd9A,271
 datarobotx/py.typed,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 datarobotx/client/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 datarobotx/client/datasets.py,sha256=l1SoA0yl2Eqbb3pQNcoa9G_sj9MK_xObxt9pt7wvON8,9402
-datarobotx/client/deployments.py,sha256=A9NMf7X25mPH5tsu-r2J6_VjLtKiJlAZgiAVaOD77LI,14621
+datarobotx/client/deployments.py,sha256=ogPqk63Tamgb22aIaHk1IkaARoVjW6h_WrQhcyDbOAs,15368
 datarobotx/client/prediction_servers.py,sha256=BS6Z1fT5ev6ldiIOxKZcuELGcT2k5scZ5j8VH7q3ads,1002
-datarobotx/client/projects.py,sha256=85ytqyR3g219bULSvoi-P9gvp0_1-8y6EOutccLb5GE,24966
+datarobotx/client/projects.py,sha256=3bVdOMN8tTNrIYcyB7_KdlTghjy02fcSEkxPKmNj5W8,25695
 datarobotx/client/status.py,sha256=ExkEDpnBbyQCemp2r4cptUMzwhM5o3F_febWq4qsmKI,2420
 datarobotx/common/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-datarobotx/common/client.py,sha256=bo3yz0KY7kSF8WZp4F8axYZRmpoFDU6iL3vPoSMgLHg,5980
-datarobotx/common/config.py,sha256=fjXENYUFQAPmuKuzdWn8usDn3oJXRdF2VVUPLHn8KKg,9306
+datarobotx/common/client.py,sha256=FCfYTdvGTdneJDcFhmDzK4ZBIf1BtmzV5vYYi0z5CkI,7273
+datarobotx/common/config.py,sha256=KZfTORwtIWimYD4yihz8E37WvwQgj2QJnuK5lIpDCFs,8741
 datarobotx/common/configurator.py,sha256=vdTL4Esk_QYyWNg31EGap7PsBvhL7QizGDVr0FEKxSo,4588
 datarobotx/common/dr_config.py,sha256=RCFE7VEMFxmSFF2Ry2NvONC4g9xh98_QChuubgaq1OI,131191
-datarobotx/common/logging.py,sha256=JjaBGsfTGwYej4FCC0jO3PBRnrQ3B5A6P7o70fgMPts,10490
+datarobotx/common/logging.py,sha256=r9vB5UAT4yGhX9jp98rtHGr3TykFS2yDYiAJvygaF6Q,10494
 datarobotx/common/transformations.py,sha256=ZZpNBmgu1jZvfrNoVtwfLsvSvwGDE5WCTrKkfYosngA,3980
-datarobotx/common/utils.py,sha256=atcDRE8eMsPsBQ6oZXrjOPpUG8EY1KpEIThuvn6u7F0,25914
+datarobotx/common/ts_helpers.py,sha256=SF1l_WxaYgt2Z6cKH5ab5WX6ExH3c4BW0aEgrm1qMz8,15032
+datarobotx/common/types.py,sha256=HJqSsXwz5kr7TeVzNc3J5vPsBwCO3pgMCkEartnoG9o,605
+datarobotx/common/utils.py,sha256=93cGtEASW7dM_IAfw1YwKUEsZNzoJDlBQoFoGGdu9CM,26936
+datarobotx/llm/__init__.py,sha256=3FvuXJ7JCHlVKIxlpw1tk7H7WfIco3Qe7vj6d55sj44,136
+datarobotx/llm/utils.py,sha256=VrHRbXIhfQgIidJ7b1r0zuw0tUbIp8-3yPpXOBoJ2HQ,2119
+datarobotx/llm/chains/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
+datarobotx/llm/chains/data_dict.py,sha256=dF-JzOvTjd3BFdyknpiGbdBZXDG0385g7RCKJLJ8PV4,11994
+datarobotx/llm/chains/enrich.py,sha256=CEGafCnHM6DJBSQxUKLKWXLOUZWsPYM159lS5VP2aI0,9398
 datarobotx/models/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 datarobotx/models/autoanomaly.py,sha256=IkhJzilTX1NWiiiEQbVgnd9rWRHnFdeUtdv03kREDXc,2754
 datarobotx/models/autocluster.py,sha256=UBwcx1_oFrlXnae4oNx3poNybmq1bBh_MPnsPbF_46w,3332
 datarobotx/models/automl.py,sha256=K3tTFn84WVdLobzDBDvEnOtyXazrIcZ86y0hN7elSho,2465
 datarobotx/models/autopilot.py,sha256=v2WlNOM55nQuaRtmCaBsnXJqlFtsfg71EAUXKkIo7BI,11349
-datarobotx/models/autots.py,sha256=6qrCfIYg_TCjNdS6VNIl_140uVqIdjlx9nGOWPgDX2g,6784
+datarobotx/models/autots.py,sha256=zf5UmPJ_M1fF_lkiB_oixQ4hWb196F1KofHHm3ym6Fw,11242
 datarobotx/models/colreduce.py,sha256=Y0gXfziUEKOtOTMgGwprl4AZAAxtAvYT3zATuWHBJWg,14976
 datarobotx/models/deploy.py,sha256=RmVGf1VmHonBjThh_BfL2TVpzW_2QDCDQqr1I_27DJs,24227
-datarobotx/models/deployment.py,sha256=1RzHLHvqRNn9rScOsugU1bXxHYRGrMfgy0wecxvhfdk,29549
-datarobotx/models/evaluation.py,sha256=EWSMBjz2b0aOFgWBJro3zCFjtbjtQtMEwPxY3o1WTbE,7869
+datarobotx/models/deployment.py,sha256=7Dd1Fi8G08lh2ztuMXmZZDRGb9vhnkwotQt-JX5ECCs,33947
+datarobotx/models/evaluation.py,sha256=zoIgR5myd42gK5w3D0pFICBBoskgeVF1moP1FfZ3_pA,7914
 datarobotx/models/featurediscovery.py,sha256=MvqXKQOKZcGNVF8lv5L1oh1JEF9bZNUmCG4vGZ1-_gk,16937
 datarobotx/models/intraproject.py,sha256=3B4d26qjwgq73HCkMLLh2m05Rtxe7mDhX1epmmFsWnM,5593
-datarobotx/models/model.py,sha256=vxI447Hh_LsUHiDdrHGr6mCxwBHcCHvP7j0_bPaCuac,26732
+datarobotx/models/model.py,sha256=owuGy1RTiRlBG2KA62LRLv6QKDj9t_0LEkaGtVhFc5Q,28420
 datarobotx/models/selfdiscovery.py,sha256=4cJ-ADXcQ1ten0ZNHVp2KvKLZ8Jb8xKIT7Dj50laPgA,9736
 datarobotx/models/share.py,sha256=DHUu-V08sDS0uLEYI35_KXkX6PHbvyJJUdOss38Bsno,4422
 datarobotx/models/sparkingest.py,sha256=E6bjHRPYzAxMwaPCRQdUFbjWodfvrTha05dpCvW0sIo,20800
 datarobotx/viz/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 datarobotx/viz/charts.py,sha256=Kw9ZSnNbNmCXk-kYioNtaAPQoNrfIvJp0Xn-Qh_NNts,4906
-datarobotx/viz/leaderboard.py,sha256=Jp9du1peJ58gn-I6F4--K3TDQVoLpLQU_yeILM8sdr4,6379
+datarobotx/viz/leaderboard.py,sha256=6pZyYdcSYAttUldsAEHY48lSZHzSbj90Z7hjysKmmes,6326
 datarobotx/viz/modelcard.py,sha256=NqTrKeCMNfo9sIi05e_SANF-2ExVO1tX5FSKe1Ucf7s,9407
 datarobotx/viz/viz.py,sha256=deS2zmkfNWl5JfLycipyF1e0aeshsXm7FDB2ZPNxbhY,9508
 datarobotx/viz/templates/drx_button.html,sha256=z2wsHdX64v0kbsleMCyo943QnEMGxi0RfHI34hyHMCg,926
 datarobotx/viz/templates/leaderboard.html,sha256=SYSaWRuNBXEzNcm0KE9TUbCo4KDHVB8wABbeQiiz3f8,1490
 datarobotx/viz/templates/leaderboard.md,sha256=QeFvLJVpLSJ1SwHF1cWdj46toXo_1ZD7OznMSG1Bx-k,414
 datarobotx/viz/templates/model_card.html,sha256=H2YKd4gNBGnaEMLCGeywx1DR6O3zvFM_ci9cxfvQ-p0,5433
 datarobotx/viz/templates/model_card.md,sha256=5Bdd7jKLEYY-hpeZ2I99C6sJwMqaeMS5jRbwLcmrCuc,48
 datarobotx/viz/templates/robot.svg,sha256=ZVruQowP1A7ri6frXGiCZnpOnY_KM8Osi66nMJAdyiM,3140
 datarobotx/viz/templates/robot_large.svg,sha256=lAbBH7yv151ngs7Y1jlMw8anqQ-PG77tzTJawLCrc3E,3135
-datarobotx-0.1.4.dist-info/METADATA,sha256=4IwJf8mF1Nyn1xO3nrJ-5Thp9VUBtpC5bWvlwItHx7E,4733
-datarobotx-0.1.4.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
-datarobotx-0.1.4.dist-info/top_level.txt,sha256=_lN2CPexvLnaRX18n5OTMk9KDKnkKNABD7EzuwyfUpI,11
-datarobotx-0.1.4.dist-info/RECORD,,
+datarobotx-0.1.5.dist-info/METADATA,sha256=jI3j3lEZzKWF57XtSbgSawVKY0R2bcx8MZjYujUJ-hM,5330
+datarobotx-0.1.5.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
+datarobotx-0.1.5.dist-info/top_level.txt,sha256=_lN2CPexvLnaRX18n5OTMk9KDKnkKNABD7EzuwyfUpI,11
+datarobotx-0.1.5.dist-info/RECORD,,
```

